{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETH_exp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "65A7Mm4gA7JA"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m00sPe0SZlEZ",
        "outputId": "248a1533-19f6-477b-8df8-5220e291d49d"
      },
      "source": [
        "!git clone https://github.com/rodrigorivera/mds20_deepfolio\r\n",
        "\r\n",
        "from mds20_deepfolio.models.NeuralHawkesProcess.DataWrapper import LOBDataset, collate_fn\r\n",
        "from mds20_deepfolio.models.NeuralHawkesProcess.model import NHPModel\r\n",
        "from mds20_deepfolio.models.NeuralHawkesProcess.train import train\r\n",
        "\r\n",
        "!unzip /content/mds20_deepfolio/models/NeuralHawkesProcess/data/LOB.zip \\\r\n",
        "      -d /content/mds20_deepfolio/models/NeuralHawkesProcess/data/\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mds20_deepfolio'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 736 (delta 3), reused 0 (delta 0), pack-reused 726\u001b[K\n",
            "Receiving objects: 100% (736/736), 69.98 MiB | 22.22 MiB/s, done.\n",
            "Resolving deltas: 100% (425/425), done.\n",
            "Archive:  /content/mds20_deepfolio/models/NeuralHawkesProcess/data/LOB.zip\n",
            "  inflating: /content/mds20_deepfolio/models/NeuralHawkesProcess/data/XRP.npy  \n",
            "  inflating: /content/mds20_deepfolio/models/NeuralHawkesProcess/data/ETH.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-hhQ7vo52if"
      },
      "source": [
        "# **ETH Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYp_Mcsa8Orq",
        "outputId": "f158c60c-737e-4cb5-a5c9-6a5379794ba6"
      },
      "source": [
        "ETH_dataset = LOBDataset('/content/mds20_deepfolio/models/NeuralHawkesProcess/data/ETH.npy')\r\n",
        "data_len = len(ETH_dataset)\r\n",
        "print(data_len, ETH_dataset[0])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "527 (tensor([14.2720, 13.3890, 27.3870,  ..., 11.3620, 23.3570,  7.3450]), tensor([1, 0, 0,  ..., 0, 0, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0VpFgiUHJmP",
        "outputId": "1bbdd160-e2ac-48ce-b109-b5703277116f"
      },
      "source": [
        "train_dataset = torch.utils.data.Subset(ETH_dataset, range(395))\r\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([14.2720, 13.3890, 27.3870,  ..., 11.3620, 23.3570,  7.3450]),\n",
              " tensor([1, 0, 0,  ..., 0, 0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1OCORlqSrjL",
        "outputId": "04a4a97e-714b-4d1f-a8ef-e9f5700a0ac1"
      },
      "source": [
        "range(395)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 395)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEpH3JsUbKun",
        "outputId": "a566fd64-4c76-4683-ef42-51b4d81cc350"
      },
      "source": [
        "train_len = int(data_len*0.75)\r\n",
        "val_len = int(data_len*0.125)\r\n",
        "test_len = data_len - train_len - val_len\r\n",
        "\r\n",
        "#train_dataset, val_dataset,test_dataset = torch.utils.data.random_split(ETH_dataset, [train_len, val_len, test_len])\r\n",
        "train_dataset = torch.utils.data.Subset(ETH_dataset, range(395))\r\n",
        "val_dataset = torch.utils.data.Subset(ETH_dataset, range(395,395+66))\r\n",
        "test_dataset = torch.utils.data.Subset(ETH_dataset, range(395+66,395+66+66))\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, batch_size=12, collate_fn=collate_fn)\r\n",
        "val_loader = DataLoader(val_dataset, batch_size=12, collate_fn=collate_fn)\r\n",
        "test_loader = DataLoader(test_dataset, batch_size=12, collate_fn=collate_fn)\r\n",
        "\r\n",
        "print('lenght of train_dataset:', len(train_dataset))\r\n",
        "print('lenght of val_dataset:', len(val_dataset))\r\n",
        "print('lenght of test_dataset:', len(test_dataset))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lenght of train_dataset: 395\n",
            "lenght of val_dataset: 66\n",
            "lenght of test_dataset: 66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6LS_HiKZ5S4"
      },
      "source": [
        "DO_TRAIN = False\r\n",
        "model = NHPModel(256, device=device).to(device)\r\n",
        "\r\n",
        "if DO_TRAIN:\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\r\n",
        "    statiscs = train(model, optimizer, train_loader, val_loader, device, n_epochs = 25, sum_losses=True)\r\n",
        "else:\r\n",
        "    model.load_state_dict(torch.load('/content/mds20_deepfolio/models/NeuralHawkesProcess/weights/ETH,256.pth'))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keOl3Xt1r54V"
      },
      "source": [
        "# **Evaluate model using Linear layer for time and type prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4N9hnjtimSj"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "loss_time, type_acc,loss_llh = 0, 0,0\r\n",
        "for event_seq, time_seq in test_loader:\r\n",
        "    event_seq, time_seq = event_seq.to(device), time_seq.to(device)\r\n",
        "    intens, time, event = model.forward(event_seq, time_seq)\r\n",
        "\r\n",
        "    loss_llh += model.LogLikelihoodLoss(intens, time_seq) / (time_seq.shape[0] * time_seq.shape[1])\r\n",
        "    loss_time += model.time_loss(time, time_seq)\r\n",
        "    type_acc += accuracy_score(event[:,:-1].argmax(dim=2).cpu().reshape(-1), \r\n",
        "                                                  event_seq[:, 1:].cpu().reshape(-1))\r\n",
        "\r\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kXbSFTNlx3B",
        "outputId": "7115ff34-39d5-4ce8-f5da-21ee3327eedc"
      },
      "source": [
        "print('Time RMSE on test dataset', (loss_time/len(test_loader)).item()**0.5)\r\n",
        "print('Type prediction accuracy on test dataset', type_acc/len(test_loader))\r\n",
        "print('Log-likelihood on test dataset', -(loss_llh/len(test_loader)).item())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time RMSE on test dataset 17.859185325436354\n",
            "Type prediction accuracy on test dataset 0.5726342592592591\n",
            "Log-likelihood on test dataset -8.170878410339355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQlGbhAWtBdV"
      },
      "source": [
        "# **Evaluate model using probability function for time and type prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcHGRMSokY55"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, mean_squared_error\r\n",
        "\r\n",
        "def evaluate_prediction(model, dataloader, device):\r\n",
        "        \"\"\"\r\n",
        "        Evalute prediction on give dataset\r\n",
        "        Will compute mse and accuracy score for event time and type prediction.\r\n",
        "        Input:\r\n",
        "           model - NHP model to compute decay states for sequence\r\n",
        "           dataloader - dataloader with data\r\n",
        "        Output:\r\n",
        "           mean_squared_error - for event time prediction\r\n",
        "           accuracy_score - for event type prediction\r\n",
        "        \"\"\"\r\n",
        "        pred_data = []\r\n",
        "        for event_seqs, time_seqs in dataloader:\r\n",
        "            for i in range(len(event_seqs)):\r\n",
        "                pred_data.append(predict_event(model, time_seqs[i], event_seqs[i], len(time_seqs[i])-1, device)[:4])\r\n",
        "\r\n",
        "        pred_data = np.array(pred_data)\r\n",
        "        time_gt, time_pred = pred_data[:,0], pred_data[:,1]\r\n",
        "        type_gt, type_pred = pred_data[:,2], pred_data[:,3]\r\n",
        "\r\n",
        "        time_mse_error = mean_squared_error(time_gt, time_pred)\r\n",
        "        type_accuracy = accuracy_score(type_gt, type_pred)\r\n",
        "\r\n",
        "        return time_mse_error, type_accuracy\r\n",
        "\r\n",
        "def predict_event(model, seq_time, seq_events, seq_length, device, hmax = 40,\r\n",
        "                     n_samples=1000):\r\n",
        "        \"\"\" \r\n",
        "        Predict last event time and type for the given sequence \r\n",
        "        Last event takes as unknown and model feeds with all remain sequence.\r\n",
        "        Input:\r\n",
        "            model - NHP model to compute decay states for sequence\r\n",
        "            seq_time - torch.tensor with time diffs between events in sequence\r\n",
        "            seq_events - torch.tensor with event types for each time point\r\n",
        "            seq_length - length of the sequence\r\n",
        "        \r\n",
        "        Output:\r\n",
        "            pred_dt - predicted dt for next event\r\n",
        "            gt_dt - gt df of next event\r\n",
        "            pred_type - predicted type of next event\r\n",
        "            gt_type - gt_type of next event\r\n",
        "            time_between_events - np.array - generated timestamps\r\n",
        "            intensity - np.array - intensity after event\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        \"\"\" Feed the model with sequence and compute decay cell state \"\"\"\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            model.init_states(1)\r\n",
        "            for i in range(seq_length):\r\n",
        "                c_t, c_target, output, decay = model.CTLSTM_cell(model.Embedding(seq_events[i].to(device)).unsqueeze(0), model.hidden_decay, \r\n",
        "                                                               model.cell_decay, model.cell_target)\r\n",
        "\r\n",
        "                if i < seq_length - 1:\r\n",
        "\r\n",
        "                    c_t = c_t * torch.exp(-decay * seq_time[i, None].to(device)) \r\n",
        "                    h_t = output * torch.tanh(c_t)\r\n",
        "\r\n",
        "            # gt last and one before last event types and times\r\n",
        "            last_type, gt_type = seq_events[i], seq_events[i + 1]\r\n",
        "            gt_dt = seq_time[i]\r\n",
        "\r\n",
        "\r\n",
        "            \"\"\" Make prediction for the next event time and type \"\"\"\r\n",
        "            model.eval()\r\n",
        "            timestep = hmax / n_samples\r\n",
        "\r\n",
        "            # 1) Compute intensity\r\n",
        "            time_between_events = torch.linspace(0, hmax, n_samples + 1).to(device)\r\n",
        "            hidden_vals = h_t * torch.exp(-decay * time_between_events[:, None])\r\n",
        "            intensity = model.intensity_layer(hidden_vals.to(device))\r\n",
        "            intensity_sum = intensity.sum(dim=1)\r\n",
        "\r\n",
        "\r\n",
        "            # 2) Compute density via integral \r\n",
        "            density = torch.cumsum(timestep * intensity.sum(dim=1), dim=0)\r\n",
        "            density = intensity_sum * torch.exp(-density)\r\n",
        "\r\n",
        "            # 3) Predict time of the next event via trapeze method\r\n",
        "            t = time_between_events * density   \r\n",
        "            pred_dt = (timestep * 0.5 * (t[1:] + t[:-1])).sum() \r\n",
        "            # 4) Predict type of the event via trapeze method\r\n",
        "            P = intensity / intensity_sum[:, None] * density[:, None]  \r\n",
        "            pred_type = torch.argmax(timestep * 0.5 * (P[1:] + P[:-1])).sum(dim=0)\r\n",
        "\r\n",
        "            return pred_dt.cpu().numpy(), gt_dt.cpu().numpy(), pred_type.cpu().numpy(), gt_type.cpu().numpy(), \\\r\n",
        "                            time_between_events.cpu().numpy(), intensity.cpu().numpy()\r\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25So0fhlmgqI"
      },
      "source": [
        "time_mse_error_test, type_accuracy_test = evaluate_prediction(model, test_loader,device)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wk7YC4fmx8Q",
        "outputId": "1656c45e-6e53-4f06-b75c-aa81b05ba873"
      },
      "source": [
        "print('Time RMSE on test dataset', time_mse_error_test**0.5)\r\n",
        "print('Type prediction accuracy on test dataset', type_accuracy_test)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time RMSE on test dataset 36.55562393610459\n",
            "Type prediction accuracy on test dataset 0.42424242424242425\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}