{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hawkey_process.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw_v7Utm5WWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d38b46-697c-422b-be5f-a520d310bd32"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "\n",
        "import google.colab\n",
        "google.colab.drive.mount(\"/content/drive\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATADIR = '/content/drive/MyDrive/seq_data/data_bookorder/'"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPDKdnTki2HQ"
      },
      "source": [
        "class CTLSTMDataset(Dataset):\n",
        "    ''' Dataset class for neural hawkes data\n",
        "    '''\n",
        "    def __init__(self, file_path):\n",
        "        self.seq_type = []\n",
        "        self.seq_time = []\n",
        "\n",
        "        with open(file_path, 'rb') as f:\n",
        "\n",
        "            if 'dev' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['dev']\n",
        "            elif 'train' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['train']\n",
        "            elif 'test' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['test']\n",
        "\n",
        "            for idx, seq in enumerate(seqs):\n",
        "                self.seq_type.append(torch.LongTensor([int(event['type_event']) for event in seq]))\n",
        "                self.seq_time.append(torch.FloatTensor([float(event['time_since_last_event']) for event in seq]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seq_type)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        sample = {'seq_type': self.seq_type[index], 'seq_time': self.seq_time[index]}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbM4BGZ0a_L9"
      },
      "source": [
        "dataset = CTLSTMDataset('/content/drive/MyDrive/Копия train.pkl')\n",
        "#old_loader = DataLoader(dataset, batch_size=12,collate_fn=pad_batch_fn, shuffle=False)\n",
        "new_loader = DataLoader(dataset, batch_size=12, shuffle=False)\n",
        "for x in old_loader:\n",
        "  old = x\n",
        "for x in new_loader:\n",
        "  new = x"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-ETBjhyF4Sn"
      },
      "source": [
        "def pad_batch_fn(batch_data):\n",
        "\n",
        "    sorted_batch = sorted(batch_data, key=lambda x: x['seq_type'].size(), reverse=True)\n",
        "    event_seqs = [seq['seq_type'].long() for seq in sorted_batch]\n",
        "    time_seqs = [seq['seq_time'].float() for seq in sorted_batch]\n",
        "    seqs_length = torch.LongTensor(list(map(len, event_seqs)))\n",
        "    last_time_seqs = torch.stack([torch.sum(time_seq) for time_seq in time_seqs])\n",
        "    print(seqs_length)\n",
        "\n",
        "    event_seqs_tensor = torch.zeros(len(sorted_batch), seqs_length.max()).long()\n",
        "    time_seqs_tensor = torch.zeros(len(sorted_batch), seqs_length.max()).float()\n",
        "\n",
        "    for idx, (event_seq, time_seq, seqlen) in enumerate(zip(event_seqs, time_seqs, seqs_length)):\n",
        "        event_seqs_tensor[idx, :seqlen] = torch.LongTensor(event_seq)\n",
        "        time_seqs_tensor[idx, :seqlen] = torch.FloatTensor(time_seq)\n",
        "    \n",
        "    return event_seqs_tensor, time_seqs_tensor, last_time_seqs, seqs_length\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK3ojqENO_WC"
      },
      "source": [
        ""
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIqJdTHTn6wp"
      },
      "source": [
        "def pad_bos(batch_data, type_size):\n",
        "    event_seqs, time_seqs, total_time_seqs, seqs_length = batch_data\n",
        "    pad_event_seqs = torch.zeros((event_seqs.size()[0], event_seqs.size()[1]+1)).long() * type_size\n",
        "    pad_time_seqs = torch.zeros((time_seqs.size()[0], event_seqs.size()[1]+1)).float()\n",
        "\n",
        "    pad_event_seqs[:, 1:] = event_seqs.clone()\n",
        "    pad_event_seqs[:, 0] = type_size\n",
        "    pad_time_seqs[:, 1:] = time_seqs.clone()\n",
        "\n",
        "    return pad_event_seqs, pad_time_seqs, total_time_seqs, seqs_length\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsvDXBQ-oS2i"
      },
      "source": [
        "def pad_batch_fn(batch_data):\n",
        "    sorted_batch = sorted(batch_data, key=lambda x: x['seq_type'].size(), reverse=True)\n",
        "    event_seqs = [seq['seq_type'].long() for seq in sorted_batch]\n",
        "    time_seqs = [seq['seq_time'].float() for seq in sorted_batch]\n",
        "    seqs_length = torch.LongTensor(list(map(len, event_seqs)))\n",
        "    last_time_seqs = torch.stack([torch.sum(time_seq) for time_seq in time_seqs])\n",
        "\n",
        "    event_seqs_tensor = torch.zeros(len(sorted_batch), seqs_length.max()).long()\n",
        "    time_seqs_tensor = torch.zeros(len(sorted_batch), seqs_length.max()).float()\n",
        "\n",
        "    for idx, (event_seq, time_seq, seqlen) in enumerate(zip(event_seqs, time_seqs, seqs_length)):\n",
        "        event_seqs_tensor[idx, :seqlen] = torch.LongTensor(event_seq)\n",
        "        time_seqs_tensor[idx, :seqlen] = torch.FloatTensor(time_seq)\n",
        "    \n",
        "    return event_seqs_tensor, time_seqs_tensor, last_time_seqs, seqs_length\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UnZGYmJnBcC"
      },
      "source": [
        "import time\n",
        "dataset = CTLSTMDataset('/content/drive/MyDrive/Копия train.pkl')\n",
        "epoch_num = 100\n",
        "train_dataloader = DataLoader(dataset, batch_size=12,collate_fn=pad_batch_fn, shuffle=True)\n",
        "model = CTLSTM(100, 7)\n",
        "optim = torch.optim.Adam(model.parameters())\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU8XFmg4oYv6",
        "outputId": "d5b05ec6-a06d-4d3a-a43c-7204b3650ca8"
      },
      "source": [
        "for x in train_dataloader:\n",
        "  print(x)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0, 0, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 1,  ..., 1, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 0,  ..., 0, 0, 0],\n",
            "        [1, 1, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 1,  ..., 0, 0, 1]]), tensor([[0.0000, 0.0333, 0.0167,  ..., 0.0167, 0.1333, 0.3334],\n",
            "        [0.0000, 0.1000, 0.1000,  ..., 2.7166, 0.0668, 1.6832],\n",
            "        [0.0000, 0.0833, 0.2167,  ..., 0.0166, 0.0166, 0.0166],\n",
            "        ...,\n",
            "        [0.0000, 0.6333, 0.2833,  ..., 0.0166, 0.1169, 0.0500],\n",
            "        [0.0000, 0.7000, 0.0167,  ..., 0.0166, 0.0168, 0.0166],\n",
            "        [0.0000, 0.1000, 2.1333,  ..., 2.2333, 0.0834, 0.1000]]), tensor([ 993.9500, 2012.0167, 3899.3167, 2757.9001, 1780.5834, 6916.6836,\n",
            "        3602.3999, 4813.7500, 1561.6500, 4080.1333, 2834.2666, 1638.5166]), tensor([3319, 3319, 3319, 3319, 3319, 3319, 3319, 3319, 3319, 3319, 3319, 3319]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lABvj1oOvoRE"
      },
      "source": [
        "def generate_sim_time_seqs(time_seqs, seqs_length):\n",
        "    \"\"\"Generate a simulated time interval sequences from original time interval sequences based on uniform distribution\n",
        "    \n",
        "    Args:\n",
        "        time_seqs: list of torch float tensors\n",
        "    Results:\n",
        "        sim_time_seqs: list of torch float tensors\n",
        "        sim_index_seqs: list of torch long tensors\n",
        "    \"\"\"\n",
        "    sim_time_seqs = torch.zeros((time_seqs.size()[0], time_seqs.size()[1]-1)).float()\n",
        "    sim_index_seqs = torch.zeros((time_seqs.size()[0], time_seqs.size()[1]-1)).long()\n",
        "    restore_time_seqs, restore_sim_time_seqs = [], []\n",
        "    for idx, time_seq in enumerate(time_seqs):\n",
        "        restore_time_seq = torch.stack([torch.sum(time_seq[0:i]) for i in range(1,seqs_length[idx]+1)])\n",
        "        restore_sim_time_seq, _ = torch.sort(torch.empty(seqs_length[idx]-1).uniform_(0, restore_time_seq[-1]))\n",
        "        \n",
        "        sim_time_seq = torch.zeros(seqs_length[idx]-1)\n",
        "        sim_index_seq = torch.zeros(seqs_length[idx]-1).long()\n",
        "\n",
        "        for idx_t, t in enumerate(restore_time_seq):\n",
        "            indices_to_update = restore_sim_time_seq > t\n",
        "\n",
        "            sim_time_seq[indices_to_update] = restore_sim_time_seq[indices_to_update] - t\n",
        "            sim_index_seq[indices_to_update] = idx_t\n",
        "\n",
        "        restore_time_seqs.append(restore_time_seq)\n",
        "        restore_sim_time_seqs.append(restore_sim_time_seq)\n",
        "        sim_time_seqs[idx, :seqs_length[idx]-1] = sim_time_seq\n",
        "        sim_index_seqs[idx, :seqs_length[idx]-1] = sim_index_seq\n",
        "\n",
        "    return sim_time_seqs, sim_index_seqs\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfr-sqS1Srcd"
      },
      "source": [
        "class CTLSTM(nn.Module):\n",
        "    \"\"\"Continuous time LSTM network with decay function.\"\"\"\n",
        "    def __init__(self, hidden_size, type_size, batch_first=True):\n",
        "        super(CTLSTM, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.type_size = type_size\n",
        "        self.batch_first = batch_first\n",
        "        self.num_layers = 1\n",
        "\n",
        "        # Parameters\n",
        "        # recurrent cells\n",
        "        self.rec = nn.Linear(2*self.hidden_size, 7*self.hidden_size)\n",
        "        # output mapping from hidden vectors to unnormalized intensity\n",
        "        self.wa = nn.Linear(self.hidden_size, self.type_size)\n",
        "        # embedding layer for valid events, including BOS\n",
        "        self.emb = nn.Embedding(self.type_size+1, self.hidden_size)\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        self.h_d = torch.zeros(batch_size, self.hidden_size, dtype=torch.float)\n",
        "        self.c_d = torch.zeros(batch_size, self.hidden_size, dtype=torch.float)\n",
        "        self.c_bar = torch.zeros(batch_size, self.hidden_size, dtype=torch.float)\n",
        "        self.c = torch.zeros(batch_size, self.hidden_size, dtype=torch.float)\n",
        "\n",
        "    def recurrence(self, emb_event_t, h_d_tm1, c_tm1, c_bar_tm1):\n",
        "        feed = torch.cat((emb_event_t, h_d_tm1), dim=1)\n",
        "        # B * 2H\n",
        "        (gate_i,\n",
        "        gate_f,\n",
        "        gate_z,\n",
        "        gate_o,\n",
        "        gate_i_bar,\n",
        "        gate_f_bar,\n",
        "        gate_delta) = torch.chunk(self.rec(feed), 7, -1)\n",
        "\n",
        "        gate_i = torch.sigmoid(gate_i)\n",
        "        gate_f = torch.sigmoid(gate_f)\n",
        "        gate_z = torch.tanh(gate_z)\n",
        "        gate_o = torch.sigmoid(gate_o)\n",
        "        gate_i_bar = torch.sigmoid(gate_i_bar)\n",
        "        gate_f_bar = torch.sigmoid(gate_f_bar)\n",
        "        gate_delta = F.softplus(gate_delta)\n",
        "\n",
        "        c_t = gate_f * c_tm1 + gate_i * gate_z\n",
        "        c_bar_t = gate_f_bar * c_bar_tm1 + gate_i_bar * gate_z\n",
        "\n",
        "        return c_t, c_bar_t, gate_o, gate_delta\n",
        "\n",
        "    def decay(self, c_t, c_bar_t, o_t, delta_t, duration_t):\n",
        "        c_d_t = c_bar_t + (c_t - c_bar_t) * \\\n",
        "            torch.exp(-delta_t * duration_t.view(-1,1))\n",
        "\n",
        "        h_d_t = o_t * torch.tanh(c_d_t)\n",
        "\n",
        "        return c_d_t, h_d_t\n",
        "    \n",
        "    def forward(self, event_seqs, duration_seqs, batch_first = True):\n",
        "        if batch_first:\n",
        "            event_seqs = event_seqs.transpose(0,1)\n",
        "            duration_seqs = duration_seqs.transpose(0,1)\n",
        "        \n",
        "        batch_size = event_seqs.size()[1]\n",
        "        batch_length = event_seqs.size()[0]\n",
        "\n",
        "        h_list, c_list, c_bar_list, o_list, delta_list = [], [], [], [], []\n",
        "\n",
        "        for t in range(batch_length):\n",
        "            self.init_states(batch_size)\n",
        "            c, self.c_bar, o_t, delta_t = self.recurrence(self.emb(event_seqs[t]), self.h_d, self.c_d, self.c_bar)\n",
        "            self.c_d, self.h_d = self.decay(c, self.c_bar, o_t, delta_t, duration_seqs[t])\n",
        "            h_list.append(self.h_d)\n",
        "            c_list.append(c)\n",
        "            c_bar_list.append(self.c_bar)\n",
        "            o_list.append(o_t)\n",
        "            delta_list.append(delta_t)\n",
        "        h_seq = torch.stack(h_list)\n",
        "        c_seq = torch.stack(c_list)\n",
        "        c_bar_seq = torch.stack(c_bar_list)\n",
        "        o_seq = torch.stack(o_list)\n",
        "        delta_seq = torch.stack(delta_list)\n",
        "        \n",
        "        self.output = torch.stack((h_seq, c_seq, c_bar_seq, o_seq, delta_seq))\n",
        "        return self.output\n",
        "\n",
        "    def log_likelihood(self, event_seqs, sim_time_seqs, sim_index_seqs, total_time_seqs, seqs_length, batch_first=True):\n",
        "        \"\"\"Calculate log likelihood per sequence.\"\"\"\n",
        "        batch_size, batch_length = event_seqs.shape\n",
        "        h, c, c_bar, o, delta = torch.chunk(self.output, 5, 0)\n",
        "        # L * B * H\n",
        "        h = torch.squeeze(h, 0)\n",
        "        c = torch.squeeze(c, 0)\n",
        "        c_bar = torch.squeeze(c_bar, 0)\n",
        "        o = torch.squeeze(o, 0)\n",
        "        delta = torch.squeeze(delta, 0)\n",
        "\n",
        "        # Calculate the sum of log intensities of each event in the sequence\n",
        "        original_loglikelihood = torch.zeros(batch_size)\n",
        "        lambda_k = F.softplus(self.wa(h)).transpose(0, 1)\n",
        "        \n",
        "        for idx, (event_seq, seq_len) in enumerate(zip(event_seqs, seqs_length)):\n",
        "            original_loglikelihood[idx] = torch.sum(torch.log( \n",
        "                                                     lambda_k[idx, torch.arange(seq_len).long(), event_seq[1:seq_len+1]]))\n",
        "\n",
        "        # Calculate simulated loss from MCMC method\n",
        "        h_d_list = []\n",
        "        if batch_first:\n",
        "            sim_time_seqs = sim_time_seqs.transpose(0,1)\n",
        "        for idx, sim_duration in enumerate(sim_time_seqs):\n",
        "            _, h_d_idx = self.decay(c[idx], c_bar[idx], o[idx], delta[idx], sim_duration)\n",
        "            h_d_list.append(h_d_idx)            \n",
        "        h_d = torch.stack(h_d_list)\n",
        "\n",
        "        sim_lambda_k = F.softplus(self.wa(h_d)).transpose(0,1)\n",
        "        simulated_likelihood = torch.zeros(batch_size)\n",
        "        for idx, (total_time, seq_len) in enumerate(zip(total_time_seqs, seqs_length)):\n",
        "            mc_coefficient = total_time / (seq_len)\n",
        "            simulated_likelihood[idx] = mc_coefficient * torch.sum(torch.sum(sim_lambda_k[idx, torch.arange(seq_len).long(), :]))\n",
        "\n",
        "        loglikelihood = torch.sum(original_loglikelihood - simulated_likelihood)\n",
        "        return loglikelihood\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx5NEiiVCjFK"
      },
      "source": [
        "class CTLSTM(nn.Module):\n",
        "    \"\"\"Continuous time LSTM network with decay function.\"\"\"\n",
        "    def __init__(self, hidden_size, out_size, device):\n",
        "        super(CTLSTM, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.hidden_size = hidden_size\n",
        "        self.out_size = out_size\n",
        "\n",
        "        self.Linear1 = nn.Linear(2*self.hidden_size, 7*self.hidden_size)\n",
        "        self.Linear2 = nn.Linear(self.hidden_size, self.out_size)\n",
        "        self.Embedding = nn.Embedding(self.out_size+1, self.hidden_size)\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "\n",
        "        self.h_d = torch.zeros(batch_size, self.hidden_size, dtype=torch.float, device=self.device)\n",
        "        self.c_d = torch.zeros(batch_size, self.hidden_size, dtype=torch.float, device=self.device)\n",
        "        self.c_bar = torch.zeros(batch_size, self.hidden_size, dtype=torch.float, device=self.device)\n",
        "        self.c = torch.zeros(batch_size, self.hidden_size, dtype=torch.float, device=self.device)\n",
        "\n",
        "    def RNN_unit(self, event, hidden, cell, cell_target):\n",
        "\n",
        "        (input_gate, forget_gate, z_gate,\n",
        "        output_gate, input_gate_, forget_gate_,\n",
        "        decay_cell) = torch.chunk(self.Linear1(torch.cat((event, hidden), dim=1)), 7, -1)\n",
        "\n",
        "        for gate in [input_gate, forget_gate, input_gate_, forget_gate_, output_gate]:\n",
        "            gate = gate.sigmoid()\n",
        "\n",
        "        z_gate = torch.tanh(z_gate)\n",
        "        decay_cell = F.softplus(decay_cell)\n",
        "\n",
        "        cell = forget_gate * cell + input_gate * z_gate\n",
        "        cell_target = forget_gate_ * cell_target + input_gate_ * z_gate\n",
        "\n",
        "        return cell, cell_target, output_gate, decay_cell\n",
        "\n",
        "\n",
        "    def decay(self, cell, cell_target, output_gate, decay_cell, T):\n",
        "\n",
        "        cell_decay = cell_target + (cell - cell_target) * torch.exp(-decay_cell * T.view(-1,1))\n",
        "        hidden_decay = output_gate * torch.tanh(cell)\n",
        "\n",
        "        return cell_decay, hidden_decay\n",
        "\n",
        "    def forward(self, event_seqs, duration_seqs, batch_first = True):\n",
        "        if batch_first:\n",
        "            event_seqs = event_seqs.transpose(0,1)\n",
        "            duration_seqs = duration_seqs.transpose(0,1)\n",
        "        \n",
        "        batch_size = event_seqs.size()[1]\n",
        "        batch_length = event_seqs.size()[0]\n",
        "\n",
        "        h_list, c_list, c_bar_list, o_list, delta_list = [], [], [], [], []\n",
        "\n",
        "        for t in range(batch_length):\n",
        "            self.init_states(batch_size)\n",
        "            c, self.c_bar, o_t, delta_t = self.RNN_unit(self.Embedding(event_seqs[t].to(self.device)), self.h_d, self.c_d, self.c_bar)\n",
        "            self.c_d, self.h_d = self.decay(c, self.c_bar, o_t, delta_t, duration_seqs[t].to(self.device))\n",
        "            h_list.append(self.h_d)\n",
        "            c_list.append(c)\n",
        "            c_bar_list.append(self.c_bar)\n",
        "            o_list.append(o_t)\n",
        "            delta_list.append(delta_t)\n",
        "        h_seq = torch.stack(h_list)\n",
        "        c_seq = torch.stack(c_list)\n",
        "        c_bar_seq = torch.stack(c_bar_list)\n",
        "        o_seq = torch.stack(o_list)\n",
        "        delta_seq = torch.stack(delta_list)\n",
        "        \n",
        "        self.output = torch.stack((h_seq, c_seq, c_bar_seq, o_seq, delta_seq))\n",
        "        return self.output\n",
        "    \n",
        "    def calc_intensity(self, h):\n",
        "\n",
        "        intensity = F.softplus(self.Linear2(h)).transpose(0, 1)\n",
        "        return intensity\n",
        "\n",
        "\n",
        "    def log_likelihood(self, event_seqs, sim_time_seqs, sim_index_seqs, total_time_seqs, seqs_length, batch_first=True):\n",
        "        \"\"\"Calculate log likelihood per sequence.\"\"\"\n",
        "        batch_size, batch_length = event_seqs.shape\n",
        "        h, c, c_bar, o, delta = torch.chunk(self.output, 5, 0)\n",
        "        # L * B * H\n",
        "        h = torch.squeeze(h, 0)\n",
        "        c = torch.squeeze(c, 0)\n",
        "        c_bar = torch.squeeze(c_bar, 0)\n",
        "        o = torch.squeeze(o, 0)\n",
        "        delta = torch.squeeze(delta, 0)\n",
        "\n",
        "        # Calculate the sum of log intensities of each event in the sequence\n",
        "        original_loglikelihood = torch.zeros(batch_size)\n",
        "        lambda_k = calc_intensity(h)\n",
        "  \n",
        "        for idx, (event_seq, seq_len) in enumerate(zip(event_seqs, seqs_length)):\n",
        "            original_loglikelihood[idx] = torch.sum(torch.log( \n",
        "                                                     lambda_k[idx, torch.arange(seq_len).long(), event_seq[1:seq_len+1]]))\n",
        "\n",
        "        # Calculate simulated loss from MCMC method\n",
        "        h_d_list = []\n",
        "        if batch_first:\n",
        "            sim_time_seqs = sim_time_seqs.transpose(0,1)\n",
        "        for idx, sim_duration in enumerate(sim_time_seqs):\n",
        "            _, h_d_idx = self.decay(c[idx], c_bar[idx], o[idx], delta[idx], sim_duration.to(self.device))\n",
        "            h_d_list.append(h_d_idx)            \n",
        "        h_d = torch.stack(h_d_list)\n",
        "\n",
        "        sim_lambda_k = calc_intensity(h_d)\n",
        "        simulated_likelihood = torch.zeros(batch_size)\n",
        "        for idx, (total_time, seq_len) in enumerate(zip(total_time_seqs, seqs_length)):\n",
        "            mc_coefficient = total_time / (seq_len)\n",
        "            simulated_likelihood[idx] = mc_coefficient * torch.sum(torch.sum(sim_lambda_k[idx, torch.arange(seq_len).long(), :]))\n",
        "\n",
        "        loglikelihood = torch.sum(original_loglikelihood - simulated_likelihood)\n",
        "        return loglikelihood\n"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wP93P8H9mb4x",
        "outputId": "8f82c573-7595-4f06-dfdd-72d3a52fd9bf"
      },
      "source": [
        "import time\n",
        "dataset = CTLSTMDataset('/content/drive/MyDrive/Копия train.pkl')\n",
        "epoch_num = 100\n",
        "train_dataloader = DataLoader(dataset, batch_size=12,collate_fn=pad_batch_fn, shuffle=True)\n",
        "model = CTLSTM(100, 7, device).to(device)\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "        tic_epoch = time.time()\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_dev_loss = 0.0\n",
        "        train_event_num = 0\n",
        "        dev_event_num = 0\n",
        "        print('Epoch.{} starts.'.format(epoch))\n",
        "        tic_train = time.time()\n",
        "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
        "            tic_batch = time.time()\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            \n",
        "            event_seqs, time_seqs, total_time_seqs, seqs_length = pad_bos(sample_batched, model.out_size)\n",
        "            \n",
        "            sim_time_seqs, sim_index_seqs = generate_sim_time_seqs(time_seqs, seqs_length)\n",
        "            \n",
        "            model.forward(event_seqs.to(device), time_seqs.to(device))\n",
        "            likelihood = model.log_likelihood(event_seqs, sim_time_seqs, sim_index_seqs, total_time_seqs, seqs_length)\n",
        "            batch_event_num = torch.sum(seqs_length)\n",
        "            batch_loss = -likelihood\n",
        "            print(batch_loss)\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "            toc_batch = time.time()\n",
        "            if i_batch % 100 == 0:\n",
        "                print('Epoch.{} Batch.{}:\\nBatch Likelihood per event: {:5f} nats\\nTrain Time: {:2f} s'.format(epoch, i_batch, likelihood/batch_event_num, toc_batch-tic_batch))\n",
        "            epoch_train_loss += batch_loss\n",
        "            train_event_num += batch_event_num\n",
        "\n",
        "        toc_train = time.time()\n",
        "        print('---\\nEpoch.{} Training set\\nTrain Likelihood per event: {:5f} nats\\nTrainig Time:{:2f} s'.format(epoch, -epoch_train_loss/train_event_num, toc_train-tic_train))\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch.0 starts.\n",
            "tensor(161606.3125, grad_fn=<NegBackward>)\n",
            "Epoch.0 Batch.0:\n",
            "Batch Likelihood per event: -4.057606 nats\n",
            "Train Time: 9.402503 s\n",
            "tensor(407445.7812, grad_fn=<NegBackward>)\n",
            "tensor(179963.4375, grad_fn=<NegBackward>)\n",
            "tensor(445671.6875, grad_fn=<NegBackward>)\n",
            "tensor(208273.1562, grad_fn=<NegBackward>)\n",
            "tensor(183529., grad_fn=<NegBackward>)\n",
            "tensor(211309.5781, grad_fn=<NegBackward>)\n",
            "tensor(122634.5234, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.0 Training set\n",
            "Train Likelihood per event: -6.429090 nats\n",
            "Trainig Time:73.316716 s\n",
            "Epoch.1 starts.\n",
            "tensor(228105.4375, grad_fn=<NegBackward>)\n",
            "Epoch.1 Batch.0:\n",
            "Batch Likelihood per event: -5.727263 nats\n",
            "Train Time: 9.380567 s\n",
            "tensor(171710.5625, grad_fn=<NegBackward>)\n",
            "tensor(125985.6562, grad_fn=<NegBackward>)\n",
            "tensor(116376.5703, grad_fn=<NegBackward>)\n",
            "tensor(263406.5312, grad_fn=<NegBackward>)\n",
            "tensor(226281.9219, grad_fn=<NegBackward>)\n",
            "tensor(117400.4375, grad_fn=<NegBackward>)\n",
            "tensor(50966.1562, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.1 Training set\n",
            "Train Likelihood per event: -4.352828 nats\n",
            "Trainig Time:74.537377 s\n",
            "Epoch.2 starts.\n",
            "tensor(198856.3906, grad_fn=<NegBackward>)\n",
            "Epoch.2 Batch.0:\n",
            "Batch Likelihood per event: -4.992879 nats\n",
            "Train Time: 9.711688 s\n",
            "tensor(108325.1328, grad_fn=<NegBackward>)\n",
            "tensor(86903.6641, grad_fn=<NegBackward>)\n",
            "tensor(88277.3438, grad_fn=<NegBackward>)\n",
            "tensor(136677.0312, grad_fn=<NegBackward>)\n",
            "tensor(75925.6641, grad_fn=<NegBackward>)\n",
            "tensor(76140.6250, grad_fn=<NegBackward>)\n",
            "tensor(41007.3828, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.2 Training set\n",
            "Train Likelihood per event: -2.718735 nats\n",
            "Trainig Time:76.573471 s\n",
            "Epoch.3 starts.\n",
            "tensor(78147.2500, grad_fn=<NegBackward>)\n",
            "Epoch.3 Batch.0:\n",
            "Batch Likelihood per event: -1.962118 nats\n",
            "Train Time: 9.592000 s\n",
            "tensor(75170.4297, grad_fn=<NegBackward>)\n",
            "tensor(111247.6641, grad_fn=<NegBackward>)\n",
            "tensor(108577.5078, grad_fn=<NegBackward>)\n",
            "tensor(72032.1562, grad_fn=<NegBackward>)\n",
            "tensor(76670.2578, grad_fn=<NegBackward>)\n",
            "tensor(66568.6328, grad_fn=<NegBackward>)\n",
            "tensor(38568.4219, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.3 Training set\n",
            "Train Likelihood per event: -2.098967 nats\n",
            "Trainig Time:75.235019 s\n",
            "Epoch.4 starts.\n",
            "tensor(71629.0781, grad_fn=<NegBackward>)\n",
            "Epoch.4 Batch.0:\n",
            "Batch Likelihood per event: -1.798460 nats\n",
            "Train Time: 10.018149 s\n",
            "tensor(65495.4648, grad_fn=<NegBackward>)\n",
            "tensor(69072.0469, grad_fn=<NegBackward>)\n",
            "tensor(115343.7266, grad_fn=<NegBackward>)\n",
            "tensor(65062.2305, grad_fn=<NegBackward>)\n",
            "tensor(64626.5781, grad_fn=<NegBackward>)\n",
            "tensor(65930.8281, grad_fn=<NegBackward>)\n",
            "tensor(88195.6562, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.4 Training set\n",
            "Train Likelihood per event: -2.026566 nats\n",
            "Trainig Time:74.840535 s\n",
            "Epoch.5 starts.\n",
            "tensor(77948.0078, grad_fn=<NegBackward>)\n",
            "Epoch.5 Batch.0:\n",
            "Batch Likelihood per event: -1.957116 nats\n",
            "Train Time: 9.836937 s\n",
            "tensor(80272.2188, grad_fn=<NegBackward>)\n",
            "tensor(64974.0078, grad_fn=<NegBackward>)\n",
            "tensor(66742.6094, grad_fn=<NegBackward>)\n",
            "tensor(67100.6719, grad_fn=<NegBackward>)\n",
            "tensor(132416.7500, grad_fn=<NegBackward>)\n",
            "tensor(66154.0391, grad_fn=<NegBackward>)\n",
            "tensor(33637.8203, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.5 Training set\n",
            "Train Likelihood per event: -1.972636 nats\n",
            "Trainig Time:75.488419 s\n",
            "Epoch.6 starts.\n",
            "tensor(65899.5156, grad_fn=<NegBackward>)\n",
            "Epoch.6 Batch.0:\n",
            "Batch Likelihood per event: -1.654603 nats\n",
            "Train Time: 9.996651 s\n",
            "tensor(94946.0781, grad_fn=<NegBackward>)\n",
            "tensor(77661.8516, grad_fn=<NegBackward>)\n",
            "tensor(70060.2422, grad_fn=<NegBackward>)\n",
            "tensor(66815.5547, grad_fn=<NegBackward>)\n",
            "tensor(77817.2891, grad_fn=<NegBackward>)\n",
            "tensor(105060.3047, grad_fn=<NegBackward>)\n",
            "tensor(32020.0820, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.6 Training set\n",
            "Train Likelihood per event: -1.976100 nats\n",
            "Trainig Time:77.136786 s\n",
            "Epoch.7 starts.\n",
            "tensor(69078.2422, grad_fn=<NegBackward>)\n",
            "Epoch.7 Batch.0:\n",
            "Batch Likelihood per event: -1.734414 nats\n",
            "Train Time: 9.860908 s\n",
            "tensor(69184.7812, grad_fn=<NegBackward>)\n",
            "tensor(112489.8281, grad_fn=<NegBackward>)\n",
            "tensor(63653.8047, grad_fn=<NegBackward>)\n",
            "tensor(98251.9531, grad_fn=<NegBackward>)\n",
            "tensor(65795.8906, grad_fn=<NegBackward>)\n",
            "tensor(75602.6797, grad_fn=<NegBackward>)\n",
            "tensor(33000.2461, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.7 Training set\n",
            "Train Likelihood per event: -1.965309 nats\n",
            "Trainig Time:76.732888 s\n",
            "Epoch.8 starts.\n",
            "tensor(95963.1719, grad_fn=<NegBackward>)\n",
            "Epoch.8 Batch.0:\n",
            "Batch Likelihood per event: -2.409440 nats\n",
            "Train Time: 10.494069 s\n",
            "tensor(69886.1953, grad_fn=<NegBackward>)\n",
            "tensor(72136.0312, grad_fn=<NegBackward>)\n",
            "tensor(67172.7812, grad_fn=<NegBackward>)\n",
            "tensor(76155.3984, grad_fn=<NegBackward>)\n",
            "tensor(100863.0938, grad_fn=<NegBackward>)\n",
            "tensor(64567.3008, grad_fn=<NegBackward>)\n",
            "tensor(37656.2656, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.8 Training set\n",
            "Train Likelihood per event: -1.956413 nats\n",
            "Trainig Time:77.451713 s\n",
            "Epoch.9 starts.\n",
            "tensor(64440.1328, grad_fn=<NegBackward>)\n",
            "Epoch.9 Batch.0:\n",
            "Batch Likelihood per event: -1.617961 nats\n",
            "Train Time: 10.165928 s\n",
            "tensor(142247.9375, grad_fn=<NegBackward>)\n",
            "tensor(75557.3750, grad_fn=<NegBackward>)\n",
            "tensor(66170.5859, grad_fn=<NegBackward>)\n",
            "tensor(69189.4062, grad_fn=<NegBackward>)\n",
            "tensor(69093.6875, grad_fn=<NegBackward>)\n",
            "tensor(68976.5156, grad_fn=<NegBackward>)\n",
            "tensor(35723.4141, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.9 Training set\n",
            "Train Likelihood per event: -1.979843 nats\n",
            "Trainig Time:76.145832 s\n",
            "Epoch.10 starts.\n",
            "tensor(70905.7500, grad_fn=<NegBackward>)\n",
            "Epoch.10 Batch.0:\n",
            "Batch Likelihood per event: -1.780299 nats\n",
            "Train Time: 9.823296 s\n",
            "tensor(74604.4531, grad_fn=<NegBackward>)\n",
            "tensor(67140.9766, grad_fn=<NegBackward>)\n",
            "tensor(110322., grad_fn=<NegBackward>)\n",
            "tensor(60172.9414, grad_fn=<NegBackward>)\n",
            "tensor(62953.9922, grad_fn=<NegBackward>)\n",
            "tensor(66971.9609, grad_fn=<NegBackward>)\n",
            "tensor(75185.4297, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.10 Training set\n",
            "Train Likelihood per event: -1.969326 nats\n",
            "Trainig Time:76.206074 s\n",
            "Epoch.11 starts.\n",
            "tensor(111035.1875, grad_fn=<NegBackward>)\n",
            "Epoch.11 Batch.0:\n",
            "Batch Likelihood per event: -2.787868 nats\n",
            "Train Time: 9.664567 s\n",
            "tensor(64308.6250, grad_fn=<NegBackward>)\n",
            "tensor(67444.0469, grad_fn=<NegBackward>)\n",
            "tensor(71413.9922, grad_fn=<NegBackward>)\n",
            "tensor(68882.5781, grad_fn=<NegBackward>)\n",
            "tensor(60771.1445, grad_fn=<NegBackward>)\n",
            "tensor(103009.3984, grad_fn=<NegBackward>)\n",
            "tensor(39111.9141, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.11 Training set\n",
            "Train Likelihood per event: -1.961692 nats\n",
            "Trainig Time:76.948859 s\n",
            "Epoch.12 starts.\n",
            "tensor(67408.3906, grad_fn=<NegBackward>)\n",
            "Epoch.12 Batch.0:\n",
            "Batch Likelihood per event: -1.692487 nats\n",
            "Train Time: 10.145251 s\n",
            "tensor(102546.8594, grad_fn=<NegBackward>)\n",
            "tensor(65651.0078, grad_fn=<NegBackward>)\n",
            "tensor(73215.7031, grad_fn=<NegBackward>)\n",
            "tensor(64159.0938, grad_fn=<NegBackward>)\n",
            "tensor(73471.2188, grad_fn=<NegBackward>)\n",
            "tensor(104799.0156, grad_fn=<NegBackward>)\n",
            "tensor(35441.3320, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.12 Training set\n",
            "Train Likelihood per event: -1.964087 nats\n",
            "Trainig Time:76.630157 s\n",
            "Epoch.13 starts.\n",
            "tensor(66396.1875, grad_fn=<NegBackward>)\n",
            "Epoch.13 Batch.0:\n",
            "Batch Likelihood per event: -1.667073 nats\n",
            "Train Time: 10.219575 s\n",
            "tensor(70102.5234, grad_fn=<NegBackward>)\n",
            "tensor(65614.1172, grad_fn=<NegBackward>)\n",
            "tensor(72198.4844, grad_fn=<NegBackward>)\n",
            "tensor(60867.3203, grad_fn=<NegBackward>)\n",
            "tensor(68458.1641, grad_fn=<NegBackward>)\n",
            "tensor(158631.2188, grad_fn=<NegBackward>)\n",
            "tensor(32575.6172, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.13 Training set\n",
            "Train Likelihood per event: -1.991375 nats\n",
            "Trainig Time:77.805995 s\n",
            "Epoch.14 starts.\n",
            "tensor(63754.7188, grad_fn=<NegBackward>)\n",
            "Epoch.14 Batch.0:\n",
            "Batch Likelihood per event: -1.600751 nats\n",
            "Train Time: 9.851759 s\n",
            "tensor(74065.7266, grad_fn=<NegBackward>)\n",
            "tensor(65346.9844, grad_fn=<NegBackward>)\n",
            "tensor(68219.1484, grad_fn=<NegBackward>)\n",
            "tensor(97635.1875, grad_fn=<NegBackward>)\n",
            "tensor(104973.0938, grad_fn=<NegBackward>)\n",
            "tensor(70594.0859, grad_fn=<NegBackward>)\n",
            "tensor(38359.1445, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.14 Training set\n",
            "Train Likelihood per event: -1.951552 nats\n",
            "Trainig Time:76.350140 s\n",
            "Epoch.15 starts.\n",
            "tensor(70590.7812, grad_fn=<NegBackward>)\n",
            "Epoch.15 Batch.0:\n",
            "Batch Likelihood per event: -1.772391 nats\n",
            "Train Time: 9.649801 s\n",
            "tensor(64867.7031, grad_fn=<NegBackward>)\n",
            "tensor(98407.4219, grad_fn=<NegBackward>)\n",
            "tensor(72352.5938, grad_fn=<NegBackward>)\n",
            "tensor(67214.1797, grad_fn=<NegBackward>)\n",
            "tensor(80011.7188, grad_fn=<NegBackward>)\n",
            "tensor(98730.4297, grad_fn=<NegBackward>)\n",
            "tensor(33225.8398, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.15 Training set\n",
            "Train Likelihood per event: -1.959762 nats\n",
            "Trainig Time:76.813941 s\n",
            "Epoch.16 starts.\n",
            "tensor(97133.8906, grad_fn=<NegBackward>)\n",
            "Epoch.16 Batch.0:\n",
            "Batch Likelihood per event: -2.438834 nats\n",
            "Train Time: 10.009017 s\n",
            "tensor(73189.8750, grad_fn=<NegBackward>)\n",
            "tensor(75077.8125, grad_fn=<NegBackward>)\n",
            "tensor(68669.3125, grad_fn=<NegBackward>)\n",
            "tensor(67714.7812, grad_fn=<NegBackward>)\n",
            "tensor(64262.7305, grad_fn=<NegBackward>)\n",
            "tensor(102326.0469, grad_fn=<NegBackward>)\n",
            "tensor(37898.6719, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.16 Training set\n",
            "Train Likelihood per event: -1.962683 nats\n",
            "Trainig Time:77.766563 s\n",
            "Epoch.17 starts.\n",
            "tensor(68366.2969, grad_fn=<NegBackward>)\n",
            "Epoch.17 Batch.0:\n",
            "Batch Likelihood per event: -1.716539 nats\n",
            "Train Time: 10.400021 s\n",
            "tensor(68682.8750, grad_fn=<NegBackward>)\n",
            "tensor(104886.2812, grad_fn=<NegBackward>)\n",
            "tensor(106909.1406, grad_fn=<NegBackward>)\n",
            "tensor(60751.0508, grad_fn=<NegBackward>)\n",
            "tensor(64832.6992, grad_fn=<NegBackward>)\n",
            "tensor(76567.1094, grad_fn=<NegBackward>)\n",
            "tensor(34860.6562, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.17 Training set\n",
            "Train Likelihood per event: -1.961287 nats\n",
            "Trainig Time:77.977556 s\n",
            "Epoch.18 starts.\n",
            "tensor(67056.3906, grad_fn=<NegBackward>)\n",
            "Epoch.18 Batch.0:\n",
            "Batch Likelihood per event: -1.683649 nats\n",
            "Train Time: 9.993196 s\n",
            "tensor(108615.3438, grad_fn=<NegBackward>)\n",
            "tensor(68841.2188, grad_fn=<NegBackward>)\n",
            "tensor(97455.8438, grad_fn=<NegBackward>)\n",
            "tensor(68471.6484, grad_fn=<NegBackward>)\n",
            "tensor(70098.1562, grad_fn=<NegBackward>)\n",
            "tensor(66752.9922, grad_fn=<NegBackward>)\n",
            "tensor(37278.0703, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.18 Training set\n",
            "Train Likelihood per event: -1.956981 nats\n",
            "Trainig Time:77.920512 s\n",
            "Epoch.19 starts.\n",
            "tensor(76685.3281, grad_fn=<NegBackward>)\n",
            "Epoch.19 Batch.0:\n",
            "Batch Likelihood per event: -1.925413 nats\n",
            "Train Time: 10.082692 s\n",
            "tensor(138752.2500, grad_fn=<NegBackward>)\n",
            "tensor(66025.8125, grad_fn=<NegBackward>)\n",
            "tensor(66706.0859, grad_fn=<NegBackward>)\n",
            "tensor(67394.4609, grad_fn=<NegBackward>)\n",
            "tensor(67543.9922, grad_fn=<NegBackward>)\n",
            "tensor(61019.8984, grad_fn=<NegBackward>)\n",
            "tensor(43225.2422, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.19 Training set\n",
            "Train Likelihood per event: -1.966299 nats\n",
            "Trainig Time:78.245070 s\n",
            "Epoch.20 starts.\n",
            "tensor(81260.3750, grad_fn=<NegBackward>)\n",
            "Epoch.20 Batch.0:\n",
            "Batch Likelihood per event: -2.040282 nats\n",
            "Train Time: 10.384356 s\n",
            "tensor(63905.6719, grad_fn=<NegBackward>)\n",
            "tensor(76731.7422, grad_fn=<NegBackward>)\n",
            "tensor(65706.5312, grad_fn=<NegBackward>)\n",
            "tensor(61499.2969, grad_fn=<NegBackward>)\n",
            "tensor(107227.4453, grad_fn=<NegBackward>)\n",
            "tensor(104715.6797, grad_fn=<NegBackward>)\n",
            "tensor(28212.7246, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.20 Training set\n",
            "Train Likelihood per event: -1.972681 nats\n",
            "Trainig Time:78.955170 s\n",
            "Epoch.21 starts.\n",
            "tensor(106349.7500, grad_fn=<NegBackward>)\n",
            "Epoch.21 Batch.0:\n",
            "Batch Likelihood per event: -2.670226 nats\n",
            "Train Time: 10.299142 s\n",
            "tensor(69782.2578, grad_fn=<NegBackward>)\n",
            "tensor(70316.3359, grad_fn=<NegBackward>)\n",
            "tensor(64605.5742, grad_fn=<NegBackward>)\n",
            "tensor(71065.3750, grad_fn=<NegBackward>)\n",
            "tensor(69174.7188, grad_fn=<NegBackward>)\n",
            "tensor(68032.3828, grad_fn=<NegBackward>)\n",
            "tensor(68348.2891, grad_fn=<NegBackward>)\n",
            "---\n",
            "Epoch.21 Training set\n",
            "Train Likelihood per event: -1.967375 nats\n",
            "Trainig Time:79.830683 s\n",
            "Epoch.22 starts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-6e4a0e37d88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mevent_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_bos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0msim_time_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_index_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sim_time_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-eed384d75920>\u001b[0m in \u001b[0;36mgenerate_sim_time_seqs\u001b[0;34m(time_seqs, seqs_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0msim_time_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_to_update\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_sim_time_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_to_update\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0msim_index_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_to_update\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrestore_time_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_time_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg7p5TmyoGJz"
      },
      "source": [
        "x = model.forward(event_seqs, time_seqs)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sMY2QGWIoJ3C",
        "outputId": "1c9b1a1a-ea54-4d5a-8e5c-a36a6bded9c1"
      },
      "source": [
        "plt.plot(x[0][0:100,0,0].detach().numpy())"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbc4a27f400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqLn_hxQAyjo",
        "outputId": "374ee86c-1dc9-4eb5-fd8c-991ccf739d90"
      },
      "source": [
        "!git clone https://github.com/HMEIatJHU/neurawkes"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neurawkes'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 44 (delta 2), reused 0 (delta 0), pack-reused 38\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9ZOvT6tA4Qd",
        "outputId": "fbe107e4-3bf4-4d9c-fb2d-6c9682fb3802"
      },
      "source": [
        "!python2.7 /content/neurawkes/train_models.py \\\n",
        "    --Model='conttime' --FileData='/content/drive/MyDrive/seq_data/data_bookorder/fold1'\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PID is : 2808\n",
            "TIME is : 2020-11-24T16:15:46.364074\n",
            "Seed is : 12345\n",
            "Model is : conttime\n",
            "CoefL2 is : 0.0\n",
            "FileData is : /content/drive/MyDrive/seq_data/data_bookorder/fold1\n",
            "TrainRatio is : 1.0\n",
            "FilePretrain is : None\n",
            "TrackPeriod is : 1000\n",
            "MaxEpoch is : 50\n",
            "SizeBatch is : 10\n",
            "Optimizer is : adam\n",
            "LossType is : loglikehood\n",
            "WhatTrack is : loss\n",
            "LearnRate is : 0.001\n",
            "PartialPredict is : False\n",
            "PruneStream is : 0\n",
            "Dev Included Setting is: False\n",
            "PredictFirst is: True\n",
            "PredictLambda is: False\n",
            "reading and processing data ... \n",
            "initialize the data processer ... \n",
            "reading data for tag :  train\n",
            "reading data for tag :  dev\n",
            "finish data processer initialization ... \n",
            "building model ... \n",
            "get time quantiles ... \n",
            "building controller ... \n",
            "initializing Neural Hawkes with Continuous-time LSTM ... \n",
            "train with log-likelihood ... \n",
            "computing loss function of Neural Hawkes model with continuous-time LSTM ... \n",
            "creating Adam optimizer ... \n",
            "learn rate is set to :  0.001\n",
            "setting learning rate :  0.001\n",
            "computing updates ... \n",
            "updates computed ! \n",
            "optimize loglikehood ... \n",
            "compiling training function ... \n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "compiling dev function ... \n",
            "model finished, comilation time is  151.0\n",
            "building training log ... \n",
            "creating training log file ... \n",
            "training epoch  0\n",
            "shuffling training data idx ... \n",
            "/usr/local/lib/python2.7/dist-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  rval = inputs[0].__getitem__(inputs[1:])\n",
            "training epoch  1\n",
            "shuffling training data idx ... \n",
            "training epoch  2\n",
            "shuffling training data idx ... \n",
            "training epoch  3\n",
            "shuffling training data idx ... \n",
            "training epoch  4\n",
            "shuffling training data idx ... \n",
            "training epoch  5\n",
            "shuffling training data idx ... \n",
            "training epoch  6\n",
            "shuffling training data idx ... \n",
            "training epoch  7\n",
            "shuffling training data idx ... \n",
            "training epoch  8\n",
            "shuffling training data idx ... \n",
            "training epoch  9\n",
            "shuffling training data idx ... \n",
            "training epoch  10\n",
            "shuffling training data idx ... \n",
            "training epoch  11\n",
            "shuffling training data idx ... \n",
            "training epoch  12\n",
            "shuffling training data idx ... \n",
            "training epoch  13\n",
            "shuffling training data idx ... \n",
            "training epoch  14\n",
            "shuffling training data idx ... \n",
            "training epoch  15\n",
            "shuffling training data idx ... \n",
            "training epoch  16\n",
            "shuffling training data idx ... \n",
            "training epoch  17\n",
            "shuffling training data idx ... \n",
            "training epoch  18\n",
            "shuffling training data idx ... \n",
            "training epoch  19\n",
            "shuffling training data idx ... \n",
            "training epoch  20\n",
            "shuffling training data idx ... \n",
            "training epoch  21\n",
            "shuffling training data idx ... \n",
            "training epoch  22\n",
            "shuffling training data idx ... \n",
            "training epoch  23\n",
            "shuffling training data idx ... \n",
            "training epoch  24\n",
            "shuffling training data idx ... \n",
            "training epoch  25\n",
            "shuffling training data idx ... \n",
            "training epoch  26\n",
            "shuffling training data idx ... \n",
            "training epoch  27\n",
            "shuffling training data idx ... \n",
            "training epoch  28\n",
            "shuffling training data idx ... \n",
            "training epoch  29\n",
            "shuffling training data idx ... \n",
            "training epoch  30\n",
            "shuffling training data idx ... \n",
            "training epoch  31\n",
            "shuffling training data idx ... \n",
            "training epoch  32\n",
            "shuffling training data idx ... \n",
            "training epoch  33\n",
            "shuffling training data idx ... \n",
            "training epoch  34\n",
            "shuffling training data idx ... \n",
            "training epoch  35\n",
            "shuffling training data idx ... \n",
            "training epoch  36\n",
            "shuffling training data idx ... \n",
            "training epoch  37\n",
            "shuffling training data idx ... \n",
            "training epoch  38\n",
            "shuffling training data idx ... \n",
            "training epoch  39\n",
            "shuffling training data idx ... \n",
            "training epoch  40\n",
            "shuffling training data idx ... \n",
            "training epoch  41\n",
            "shuffling training data idx ... \n",
            "training epoch  42\n",
            "shuffling training data idx ... \n",
            "training epoch  43\n",
            "shuffling training data idx ... \n",
            "training epoch  44\n",
            "shuffling training data idx ... \n",
            "training epoch  45\n",
            "shuffling training data idx ... \n",
            "training epoch  46\n",
            "shuffling training data idx ... \n",
            "training epoch  47\n",
            "shuffling training data idx ... \n",
            "training epoch  48\n",
            "shuffling training data idx ... \n",
            "training epoch  49\n",
            "shuffling training data idx ... \n",
            "finish tracking log ... \n",
            "finish training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6NZ5-GlRikx",
        "outputId": "7bc2e52e-e785-4811-811a-5670ec1d8763"
      },
      "source": [
        "!python2.7 /content/neurawkes/test_models_and_save.py --Model='conttime' --FileData='/content/drive/MyDrive/seq_data/data_bookorder/fold1'\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: test_models_and_save.py [-h] -m {hawkes,hawkesinhib,conttime} -fd\n",
            "                               FILEDATA -fp FILEPRETRAIN -ts {dev,test,test1}\n",
            "                               [-s SEED] [-md MULTIPLEDEV] [-sl {0,1}]\n",
            "                               [-pp {0,1}] [-ps PRUNESTREAM] [-pf {0,1}]\n",
            "                               [-pl {0,1}] [-fg FILEGOLD]\n",
            "                               [-mg {hawkes,hawkesinhib,conttime}]\n",
            "test_models_and_save.py: error: argument -fp/--FilePretrain is required\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}