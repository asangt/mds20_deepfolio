{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preparation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLPBkdtvHfkI"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgokTqe6HjsM"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnOYtmAKIhxc"
      },
      "source": [
        "## LTC preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIOHuCDaI8-j",
        "outputId": "67aff1aa-3d4d-4afc-e9d0-1debc6411168"
      },
      "source": [
        "dataset_LTC = np.load(\"/content/drive/MyDrive/unipoint/dataset_LTC.npy\", allow_pickle = True)\r\n",
        "dataset_LTC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60470000e+04, 3.60470000e+04, 0.00000000e+00],\n",
              "       [4.18310000e+04, 7.78780000e+04, 0.00000000e+00],\n",
              "       [1.51073000e+05, 2.28951000e+05, 0.00000000e+00],\n",
              "       ...,\n",
              "       [4.12810000e+04, 3.15356062e+10, 0.00000000e+00],\n",
              "       [2.04746000e+05, 3.15358109e+10, 0.00000000e+00],\n",
              "       [1.71130000e+04, 3.15358280e+10, 1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSwU7s6IJdtK",
        "outputId": "45433ebe-d4a1-44d0-88c9-0ae82a489a68"
      },
      "source": [
        "# drop 'time from 0' column\r\n",
        "dataset_LTC = np.delete(dataset_LTC, 1, axis = 1)\r\n",
        "dataset_LTC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60470e+04, 0.00000e+00],\n",
              "       [4.18310e+04, 0.00000e+00],\n",
              "       [1.51073e+05, 0.00000e+00],\n",
              "       ...,\n",
              "       [4.12810e+04, 0.00000e+00],\n",
              "       [2.04746e+05, 0.00000e+00],\n",
              "       [1.71130e+04, 1.00000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWDh_6-IJdql",
        "outputId": "d057a0f6-0d4f-41b5-ac39-cc267b5b8597"
      },
      "source": [
        "dataset_LTC = np.transpose(dataset_LTC)\r\n",
        "dataset_LTC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60470e+04, 4.18310e+04, 1.51073e+05, ..., 4.12810e+04,\n",
              "        2.04746e+05, 1.71130e+04],\n",
              "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
              "        0.00000e+00, 1.00000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1yjGKTxM93W",
        "outputId": "eaff8db1-faaa-4436-c6a0-fb778a6ac9d2"
      },
      "source": [
        "dataset_LTC.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "901989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO0Qsa5IJdn2",
        "outputId": "6aaf80d5-d465-49a2-9084-b1a15bee4e63"
      },
      "source": [
        "time_LTC_zeros = []\r\n",
        "time_LTC_ones = []\r\n",
        "\r\n",
        "# for converting miliseconds to seconds in the first raws it is needed to divide values by 1000\r\n",
        "\r\n",
        "for i in range(dataset_LTC.shape[1]):\r\n",
        "  if dataset_LTC[1,i] == 0:\r\n",
        "    time_LTC_zeros.append(dataset_LTC[0,i]/1000)\r\n",
        "  elif dataset_LTC[1,i] == 1:\r\n",
        "    time_LTC_ones.append(dataset_LTC[0,i]/1000)\r\n",
        "\r\n",
        "line_zeros = np.zeros_like(time_LTC_zeros)\r\n",
        "line_ones = np.ones_like(time_LTC_ones)\r\n",
        "\r\n",
        "dataset_zeros = np.array([time_LTC_zeros, line_zeros])\r\n",
        "dataset_ones = np.array([time_LTC_ones, line_ones])\r\n",
        "\r\n",
        "print(dataset_zeros)\r\n",
        "print()\r\n",
        "print(dataset_ones)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 36.047  41.831 151.073 ...  14.893  41.281 204.746]\n",
            " [  0.      0.      0.    ...   0.      0.      0.   ]]\n",
            "\n",
            "[[ 98.221  57.206  38.969 ...  52.958 108.255  17.113]\n",
            " [  1.      1.      1.    ...   1.      1.      1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LQ4hWhpI9CZ",
        "outputId": "6d1d1aad-993b-4bda-c457-1341ad906720"
      },
      "source": [
        "dataset_zeros.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 461927)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj3WqFztSP3f",
        "outputId": "a19b0aee-8dee-4b4f-d495-9110a0dfea7b"
      },
      "source": [
        "dataset_ones.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 440062)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdmEOIzWG3zt"
      },
      "source": [
        "# now we need to divide prepared data into train:val:test = 60:20:20\r\n",
        "proportion_zeros = [int(0.6 * dataset_zeros.shape[1]), int(0.8 * dataset_zeros.shape[1])]\r\n",
        "proportion_ones = [int(0.6 * dataset_ones.shape[1]), int(0.8 * dataset_ones.shape[1])]\r\n",
        "\r\n",
        "# cut zeros dataset into the train, val and test\r\n",
        "dataset_zeros_split = np.hsplit(dataset_zeros, proportion_zeros)\r\n",
        "dataset_ones_split = np.hsplit(dataset_ones, proportion_ones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsmhvdMLHyTc",
        "outputId": "a82cb9ba-0e82-4b38-b796-5fc8a886a3b2"
      },
      "source": [
        "num_seq = 3319 # num of sequences in every future batch\r\n",
        "\r\n",
        "# FOR ZEROS\r\n",
        "for part_idx, part in enumerate(dataset_zeros_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_zeros = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_zeros_cut = np.hsplit(part, cut_zeros)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_zeros_cut.pop(0)\r\n",
        "  dataset_zeros_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_zeros_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/train_LTC/train_LTC_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/val_LTC/val_LTC_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/test_LTC/test_LTC_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "\r\n",
        "# FOR ONES\r\n",
        "for part_idx, part in enumerate(dataset_ones_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_ones = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_ones_cut = np.hsplit(part, cut_ones)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_ones_cut.pop(0)\r\n",
        "  dataset_ones_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_ones_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/train_LTC/train_LTC_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/val_LTC/val_LTC_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_LTC/test_LTC/test_LTC_ones_' + str(cut_idx) + '.npy', cut)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [[ 36.047  41.831 151.073 ...   9.797  10.335  38.561]\n",
            " [  0.      0.      0.    ...   0.      0.      0.   ]]\n",
            "1 [[ 3.959  9.322 27.339 ... 59.167 32.848 12.369]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "2 [[  3.142  10.755   9.834 ...  14.893  41.281 204.746]\n",
            " [  0.      0.      0.    ...   0.      0.      0.   ]]\n",
            "0 [[98.221 57.206 38.969 ... 21.887 34.529 12.957]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "1 [[ 24.981   9.455  10.907 ... 129.162 175.393  71.247]\n",
            " [  1.      1.      1.    ...   1.      1.      1.   ]]\n",
            "2 [[101.371 129.248  88.038 ...  52.958 108.255  17.113]\n",
            " [  1.      1.      1.    ...   1.      1.      1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aA9aOBeIoJf"
      },
      "source": [
        "## EOS preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AHpR427I0vm",
        "outputId": "e215eef9-a4a7-4898-ef18-1d3c342e1d93"
      },
      "source": [
        "dataset_EOS = np.load(\"/content/drive/MyDrive/unipoint/dataset_EOS.npy\", allow_pickle = True)\r\n",
        "\r\n",
        "\r\n",
        "# drop 'time from 0' column\r\n",
        "dataset_EOS = np.delete(dataset_EOS, 1, axis = 1)\r\n",
        "dataset_EOS = np.transpose(dataset_EOS)\r\n",
        "\r\n",
        "time_EOS_zeros = []\r\n",
        "time_EOS_ones = []\r\n",
        "\r\n",
        "# for converting miliseconds to seconds in the first raws it is needed to divide values by 1000\r\n",
        "\r\n",
        "for i in range(dataset_EOS.shape[1]):\r\n",
        "  if dataset_EOS[1,i] == 0:\r\n",
        "    time_EOS_zeros.append(dataset_EOS[0,i]/1000)\r\n",
        "  elif dataset_EOS[1,i] == 1:\r\n",
        "    time_EOS_ones.append(dataset_EOS[0,i]/1000)\r\n",
        "\r\n",
        "line_zeros = np.zeros_like(time_EOS_zeros)\r\n",
        "line_ones = np.ones_like(time_EOS_ones)\r\n",
        "\r\n",
        "dataset_zeros = np.array([time_EOS_zeros, line_zeros])\r\n",
        "dataset_ones = np.array([time_EOS_ones, line_ones])\r\n",
        "\r\n",
        "print(dataset_zeros)\r\n",
        "print()\r\n",
        "print(dataset_ones)\r\n",
        "\r\n",
        "dataset_zeros.shape\r\n",
        "dataset_ones.shape\r\n",
        "\r\n",
        "# now we need to divide prepared data into train:val:test = 60:20:20\r\n",
        "proportion_zeros = [int(0.6 * dataset_zeros.shape[1]), int(0.8 * dataset_zeros.shape[1])]\r\n",
        "proportion_ones = [int(0.6 * dataset_ones.shape[1]), int(0.8 * dataset_ones.shape[1])]\r\n",
        "\r\n",
        "# cut zeros dataset into the train, val and test\r\n",
        "dataset_zeros_split = np.hsplit(dataset_zeros, proportion_zeros)\r\n",
        "dataset_ones_split = np.hsplit(dataset_ones, proportion_ones)\r\n",
        "num_seq = 3319 # num of sequences in every future batch\r\n",
        "\r\n",
        "# FOR ZEROS\r\n",
        "for part_idx, part in enumerate(dataset_zeros_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_zeros = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_zeros_cut = np.hsplit(part, cut_zeros)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_zeros_cut.pop(0)\r\n",
        "  dataset_zeros_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_zeros_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/train_EOS/train_EOS_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/val_EOS/val_EOS_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/test_EOS/test_EOS_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "\r\n",
        "# FOR ONES\r\n",
        "for part_idx, part in enumerate(dataset_ones_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_ones = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_ones_cut = np.hsplit(part, cut_ones)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_ones_cut.pop(0)\r\n",
        "  dataset_ones_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_ones_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/train_EOS/train_EOS_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/val_EOS/val_EOS_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_EOS/test_EOS/test_EOS_ones_' + str(cut_idx) + '.npy', cut)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  56.914   11.428   29.426 ...  516.549  177.156 1362.134]\n",
            " [   0.       0.       0.    ...    0.       0.       0.   ]]\n",
            "\n",
            "[[ 17.598  14.441  96.329 ... 488.478 128.664 990.835]\n",
            " [  1.      1.      1.    ...   1.      1.      1.   ]]\n",
            "0 [[56.914 11.428 29.426 ... 17.61  18.524 12.906]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "1 [[  6.752  11.854  12.483 ... 110.148  60.012  50.523]\n",
            " [  0.      0.      0.    ...   0.      0.      0.   ]]\n",
            "2 [[  95.326   73.795   74.946 ...  516.549  177.156 1362.134]\n",
            " [   0.       0.       0.    ...    0.       0.       0.   ]]\n",
            "0 [[17.598 14.441 96.329 ...  9.933  9.367 30.375]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "1 [[16.38  25.336 11.403 ...  2.116  3.948  6.946]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "2 [[ 13.006  25.64   10.156 ... 488.478 128.664 990.835]\n",
            " [  1.      1.      1.    ...   1.      1.      1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osui7MVxIgf6"
      },
      "source": [
        "## ETH preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgIq_YhFZTHR",
        "outputId": "8d78199a-6676-4884-93bc-23cb89a64baa"
      },
      "source": [
        "dataset_ETH = np.load(\"/content/drive/MyDrive/unipoint/dataset_filtered_ETH.npy\", allow_pickle = True)\r\n",
        "print(dataset_ETH.shape)\r\n",
        "dataset_ETH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(527, 3000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.42720000e+04, 1.42720000e+04, 1.00000000e+00],\n",
              "        [1.33890000e+04, 2.76610000e+04, 0.00000000e+00],\n",
              "        [2.73870000e+04, 5.50480000e+04, 0.00000000e+00],\n",
              "        ...,\n",
              "        [1.13620000e+04, 7.58121140e+07, 0.00000000e+00],\n",
              "        [2.33570000e+04, 7.58354710e+07, 0.00000000e+00],\n",
              "        [7.34500000e+03, 7.58428160e+07, 1.00000000e+00]],\n",
              "\n",
              "       [[1.48670000e+04, 7.58576830e+07, 1.00000000e+00],\n",
              "        [2.38870000e+04, 7.58815700e+07, 1.00000000e+00],\n",
              "        [5.42900000e+03, 7.58869990e+07, 1.00000000e+00],\n",
              "        ...,\n",
              "        [1.23110000e+04, 1.21968785e+08, 0.00000000e+00],\n",
              "        [1.87530000e+04, 1.21987538e+08, 1.00000000e+00],\n",
              "        [1.44190000e+04, 1.22001957e+08, 1.00000000e+00]],\n",
              "\n",
              "       [[8.20800000e+03, 1.22010165e+08, 0.00000000e+00],\n",
              "        [4.40500000e+03, 1.22014570e+08, 0.00000000e+00],\n",
              "        [9.40300000e+03, 1.22023973e+08, 0.00000000e+00],\n",
              "        ...,\n",
              "        [5.06200000e+03, 1.49642586e+08, 1.00000000e+00],\n",
              "        [3.09500000e+03, 1.49645681e+08, 1.00000000e+00],\n",
              "        [1.17200000e+03, 1.49646853e+08, 0.00000000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.16940000e+04, 3.07805427e+10, 1.00000000e+00],\n",
              "        [9.24400000e+03, 3.07805520e+10, 1.00000000e+00],\n",
              "        [2.81360000e+04, 3.07805801e+10, 1.00000000e+00],\n",
              "        ...,\n",
              "        [2.88020000e+04, 3.08376021e+10, 1.00000000e+00],\n",
              "        [1.87200000e+04, 3.08376208e+10, 0.00000000e+00],\n",
              "        [8.58500000e+03, 3.08376294e+10, 0.00000000e+00]],\n",
              "\n",
              "       [[3.70570000e+04, 3.10480134e+10, 1.00000000e+00],\n",
              "        [2.58070000e+04, 3.10480392e+10, 1.00000000e+00],\n",
              "        [1.15820000e+04, 3.10480508e+10, 0.00000000e+00],\n",
              "        ...,\n",
              "        [2.55280000e+04, 3.11318489e+10, 0.00000000e+00],\n",
              "        [2.54960000e+04, 3.11318744e+10, 0.00000000e+00],\n",
              "        [2.64750000e+04, 3.11319009e+10, 1.00000000e+00]],\n",
              "\n",
              "       [[2.99440000e+04, 3.13323880e+10, 1.00000000e+00],\n",
              "        [4.13930000e+04, 3.13324294e+10, 0.00000000e+00],\n",
              "        [2.36870000e+04, 3.13324531e+10, 1.00000000e+00],\n",
              "        ...,\n",
              "        [5.29500000e+03, 3.13981226e+10, 0.00000000e+00],\n",
              "        [9.34700000e+03, 3.13981319e+10, 1.00000000e+00],\n",
              "        [8.67800000e+03, 3.13981406e+10, 1.00000000e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH3sxU-FZz4T"
      },
      "source": [
        "# drop 'time from 0' column\r\n",
        "dataset_ETH = np.delete(dataset_ETH[:,:,], 1, axis = 2)\r\n",
        "dataset_ETH = dataset_ETH.reshape(-1,2)\r\n",
        "dataset_ETH = np.transpose(dataset_ETH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HutTBEi5Z3E4",
        "outputId": "fc888d44-9960-4273-88ca-d3977deacadf"
      },
      "source": [
        "dataset_ETH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4272e+04, 1.3389e+04, 2.7387e+04, ..., 5.2950e+03, 9.3470e+03,\n",
              "        8.6780e+03],\n",
              "       [1.0000e+00, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 1.0000e+00,\n",
              "        1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Es8NEdXHP1",
        "outputId": "737be0b3-b30b-4c44-bf76-043d417fbce8"
      },
      "source": [
        "time_ETH_zeros = []\r\n",
        "time_ETH_ones = []\r\n",
        "\r\n",
        "# for converting miliseconds to seconds in the first raws it is needed to divide values by 1000\r\n",
        "\r\n",
        "for i in range(dataset_ETH.shape[1]):\r\n",
        "  if dataset_ETH[1,i] == 0:\r\n",
        "    time_ETH_zeros.append(dataset_ETH[0,i]/1000)\r\n",
        "  elif dataset_ETH[1,i] == 1:\r\n",
        "    time_ETH_ones.append(dataset_ETH[0,i]/1000)\r\n",
        "\r\n",
        "line_zeros = np.zeros_like(time_ETH_zeros)\r\n",
        "line_ones = np.ones_like(time_ETH_ones)\r\n",
        "\r\n",
        "dataset_zeros = np.array([time_ETH_zeros, line_zeros])\r\n",
        "dataset_ones = np.array([time_ETH_ones, line_ones])\r\n",
        "\r\n",
        "print(dataset_zeros)\r\n",
        "print()\r\n",
        "print(dataset_ones)\r\n",
        "\r\n",
        "dataset_zeros.shape\r\n",
        "dataset_ones.shape\r\n",
        "\r\n",
        "# now we need to divide prepared data into train:val:test = 60:20:20\r\n",
        "proportion_zeros = [int(0.6 * dataset_zeros.shape[1]), int(0.8 * dataset_zeros.shape[1])]\r\n",
        "proportion_ones = [int(0.6 * dataset_ones.shape[1]), int(0.8 * dataset_ones.shape[1])]\r\n",
        "\r\n",
        "# cut zeros dataset into the train, val and test\r\n",
        "dataset_zeros_split = np.hsplit(dataset_zeros, proportion_zeros)\r\n",
        "dataset_ones_split = np.hsplit(dataset_ones, proportion_ones)\r\n",
        "num_seq = 3319 # num of sequences in every future batch\r\n",
        "\r\n",
        "# FOR ZEROS\r\n",
        "for part_idx, part in enumerate(dataset_zeros_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_zeros = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_zeros_cut = np.hsplit(part, cut_zeros)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_zeros_cut.pop(0)\r\n",
        "  dataset_zeros_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_zeros_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/train_ETH/train_ETH_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/val_ETH/val_ETH_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/test_ETH/test_ETH_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "\r\n",
        "# FOR ONES\r\n",
        "for part_idx, part in enumerate(dataset_ones_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_ones = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_ones_cut = np.hsplit(part, cut_ones)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_ones_cut.pop(0)\r\n",
        "  dataset_ones_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_ones_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/train_ETH/train_ETH_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/val_ETH/val_ETH_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_ETH/test_ETH/test_ETH_ones_' + str(cut_idx) + '.npy', cut)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13.389 27.387 11.675 ...  9.016 21.031  5.295]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "\n",
            "[[14.272 12.05  16.608 ... 12.158  9.347  8.678]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "0 [[13.389 27.387 11.675 ... 34.997 13.486 16.646]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "1 [[21.735 31.121 14.594 ... 20.837 69.819 22.316]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "2 [[25.528 25.284  6.598 ...  9.016 21.031  5.295]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
            "0 [[14.272 12.05  16.608 ... 12.433 27.342 13.361]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "1 [[25.574  8.531 39.553 ... 25.434 44.177 19.299]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n",
            "2 [[46.535 33.063 26.747 ... 12.158  9.347  8.678]\n",
            " [ 1.     1.     1.    ...  1.     1.     1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GteTy9wrRnt_"
      },
      "source": [
        "## Data with bids preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0oxSDxkRovk",
        "outputId": "a09ee13b-df2e-4ced-fb3e-2723e7e13921"
      },
      "source": [
        "dataset_transact = np.load(\"/content/drive/MyDrive/unipoint/transact_dataset_ETH.npy\", allow_pickle = True)\r\n",
        "dataset_transact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[          0,           0,           1],\n",
              "       [        477,         477,           0],\n",
              "       [       1176,         699,           1],\n",
              "       ...,\n",
              "       [31535986960,        8189,           1],\n",
              "       [31535992147,        5187,           1],\n",
              "       [31535995183,        3036,           1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbh0GYHXRpxL",
        "outputId": "7dd65c6d-8749-4f37-de99-4c4494226afe"
      },
      "source": [
        "# drop 'time from 0' column\r\n",
        "dataset_transact = np.delete(dataset_transact, 0, axis = 1)\r\n",
        "dataset_transact = np.transpose(dataset_transact)\r\n",
        "\r\n",
        "time_transact_zeros = []\r\n",
        "time_transact_ones = []\r\n",
        "\r\n",
        "# for converting miliseconds to seconds in the first raws it is needed to divide values by 1000\r\n",
        "\r\n",
        "for i in range(dataset_transact.shape[1]):\r\n",
        "  if dataset_transact[1,i] == 0:\r\n",
        "    time_transact_zeros.append(dataset_transact[0,i]/1000)\r\n",
        "  elif dataset_transact[1,i] == 1:\r\n",
        "    time_transact_ones.append(dataset_transact[0,i]/1000)\r\n",
        "\r\n",
        "line_zeros = np.zeros_like(time_transact_zeros)\r\n",
        "line_ones = np.ones_like(time_transact_ones)\r\n",
        "\r\n",
        "dataset_zeros = np.array([time_transact_zeros, line_zeros])\r\n",
        "dataset_ones = np.array([time_transact_ones, line_ones])\r\n",
        "\r\n",
        "print(dataset_zeros)\r\n",
        "print()\r\n",
        "print(dataset_ones)\r\n",
        "\r\n",
        "dataset_zeros.shape\r\n",
        "dataset_ones.shape\r\n",
        "\r\n",
        "# now we need to divide prepared data into train:val:test = 60:20:20\r\n",
        "proportion_zeros = [int(0.6 * dataset_zeros.shape[1]), int(0.8 * dataset_zeros.shape[1])]\r\n",
        "proportion_ones = [int(0.6 * dataset_ones.shape[1]), int(0.8 * dataset_ones.shape[1])]\r\n",
        "\r\n",
        "# cut zeros dataset into the train, val and test\r\n",
        "dataset_zeros_split = np.hsplit(dataset_zeros, proportion_zeros)\r\n",
        "dataset_ones_split = np.hsplit(dataset_ones, proportion_ones)\r\n",
        "num_seq = 3319 # num of sequences in every future batch\r\n",
        "\r\n",
        "# FOR ZEROS\r\n",
        "for part_idx, part in enumerate(dataset_zeros_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_zeros = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_zeros_cut = np.hsplit(part, cut_zeros)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_zeros_cut.pop(0)\r\n",
        "  dataset_zeros_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_zeros_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/train_transact/train_transact_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/val_transact/val_transact_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/test_transact/test_transact_zeros_' + str(cut_idx) + '.npy', cut)\r\n",
        "\r\n",
        "# FOR ONES\r\n",
        "for part_idx, part in enumerate(dataset_ones_split):\r\n",
        "  print(part_idx, part)\r\n",
        "  \r\n",
        "  # cut each part (train, val, test) into the 'num_seq' length\r\n",
        "  cut_ones = [i for i in range(0, part.shape[1], num_seq)]\r\n",
        "  dataset_ones_cut = np.hsplit(part, cut_ones)\r\n",
        "  # removing unneeded stuff\r\n",
        "  dataset_ones_cut.pop(0)\r\n",
        "  dataset_ones_cut.pop(-1)\r\n",
        "\r\n",
        "  # recording all the values \r\n",
        "  for cut_idx, cut in enumerate(dataset_ones_cut):\r\n",
        "    if part_idx == 0:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/train_transact/train_transact_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 1:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/val_transact/val_transact_ones_' + str(cut_idx) + '.npy', cut)\r\n",
        "    if part_idx == 2:\r\n",
        "      np.save('/content/drive/MyDrive/unipoint/data/data_transact/test_transact/test_transact_ones_' + str(cut_idx) + '.npy', cut)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.477 0.68  2.179 ... 2.119 4.656 8.042]\n",
            " [0.    0.    0.    ... 0.    0.    0.   ]]\n",
            "\n",
            "[[0.    0.699 0.818 ... 8.189 5.187 3.036]\n",
            " [1.    1.    1.    ... 1.    1.    1.   ]]\n",
            "0 [[0.477 0.68  2.179 ... 0.112 0.817 0.   ]\n",
            " [0.    0.    0.    ... 0.    0.    0.   ]]\n",
            "1 [[0.635 0.144 0.08  ... 0.276 0.204 0.   ]\n",
            " [0.    0.    0.    ... 0.    0.    0.   ]]\n",
            "2 [[0.    1.193 1.02  ... 2.119 4.656 8.042]\n",
            " [0.    0.    0.    ... 0.    0.    0.   ]]\n",
            "0 [[0.    0.699 0.818 ... 0.    0.433 0.137]\n",
            " [1.    1.    1.    ... 1.    1.    1.   ]]\n",
            "1 [[0.343 0.153 0.211 ... 0.311 0.212 1.005]\n",
            " [1.    1.    1.    ... 1.    1.    1.   ]]\n",
            "2 [[0.886 1.758 0.679 ... 8.189 5.187 3.036]\n",
            " [1.    1.    1.    ... 1.    1.    1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM2lSDpeIRa-"
      },
      "source": [
        ""
      ]
    }
  ]
}