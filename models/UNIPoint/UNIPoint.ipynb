{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIPoint",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Yfy2B76Z9Y"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgRk_PwDD4ct"
      },
      "source": [
        "# UNIPoint model\n",
        "#-------------------------------------------------------\n",
        "# dimensions be like:\n",
        "#-------------------------------------------------------\n",
        "# input -> hidden state -> parameters -> basis functions -> intensity function (output)\n",
        "#-------------------------------------------------------\n",
        "# (batch_size, seq_len, n_features) -> [for iteration we take input] (batch_size, 1, n_features) ->\n",
        "# -> (batch_size, 1, 1) -> (batch_size, 1, n_parameters * n_basis_functions) -> \n",
        "# -> (batch_size, 1, n_basis_functions) -> (batch_size, 1, 1) \n",
        "#-------------------------------------------------------\n",
        "\n",
        "\n",
        "class UNIPoint(nn.Module):\n",
        "    def __init__(self, batch_size, seq_len, n_features, n_parameters, n_basis_functions):\n",
        "      \"\"\"\n",
        "      Input parameters:\n",
        "      n_neurons - number of neurons inside RNN\n",
        "      n_parameters - expecteed number of parameters in basis function\n",
        "      n_basis_functions - number of basis functions\n",
        "      \"\"\"\n",
        "      super(UNIPoint, self).__init__()\n",
        "\n",
        "      self.rnn = nn.RNNCell(n_features, 1)\n",
        "      self.hx = torch.randn(batch_size, 1) # initialize hidden state \n",
        "      self.h2p = nn.Linear(1, n_parameters * n_basis_functions)\n",
        "      self.basis_res = torch.randn(batch_size, n_basis_functions) #initialize matrix for basis f-s calculations results\n",
        "      self.Softplus = torch.nn.Softplus(beta = 1)\n",
        "\n",
        "      self.seq_len = seq_len\n",
        "      self.n_basis_functions = n_basis_functions\n",
        "\n",
        "    def ReLU(self, parameter_1, parameter_2, time):\n",
        "      \"\"\"Function to apply Rectified Linear Unit (ReLU) as basis function inside network \n",
        "        Input parameters:\n",
        "          parameters - alpha, beta for basis function's value calculation\n",
        "          time - column-vector with time which had been spent since the begining of \n",
        "                  temporal point process (TPP)\n",
        "      \"\"\"\n",
        "      self.output = torch.relu(self.parameters[:,parameter_1] * time + self.parameters[:,parameter_2] ) \n",
        "      return self.output\n",
        "    \n",
        "    def PowerLaw(self, parameter_1, parameter_2, time): # need to fix (see ReLU parameters and do the same)\n",
        "      \"\"\"Function to apply Power Law (PL) as basis function inside network \n",
        "        Input parameters:\n",
        "          parameters - alpha, beta for basis function's value calculation\n",
        "          time - column-vector with time which had been spent since the begining of \n",
        "                  temporal point process (TPP)\n",
        "      \"\"\"\n",
        "      self.output = self.parameters[:,parameter_1] * (1 + time)**( - self.parameters[:,parameter_2])\n",
        "      return self.output\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "      \"\"\"Input parameters:\n",
        "          X - batch with data \n",
        "          time - column-vector with interarrival time in temporal point process (TPP)\n",
        "      \"\"\"\n",
        "        \n",
        "      hidden_states, intensity_values = [], []\n",
        "      \n",
        "      # for each time step (here X shape is (batch_size, seq_len, n_features) )\n",
        "      for i in range(self.seq_len):\n",
        "\n",
        "          self.hx = self.rnn(X[:,i,:], self.hx)\n",
        "          self.parameters = self.h2p(self.hx)\n",
        "          \n",
        "          for function in range(self.n_basis_functions): \n",
        "              # calculating numbers of parameters to take for basis function\n",
        "              par1 = 2 * function\n",
        "              par2 = 2 * function + 1\n",
        "              self.basis_res[:, function] = self.ReLU(par1, par2, X[:,i,1]) # here X[:,i,1] - tau\n",
        "          \n",
        "          self.sum_res = torch.sum(self.basis_res, 1)\n",
        "\n",
        "          self.intensity_res = self.Softplus(self.sum_res)\n",
        "\n",
        "          hidden_states.append(self.hx)\n",
        "          intensity_values.append(self.intensity_res)\n",
        "          \n",
        "          print(\"Sequence \", i+1, \"out of\", X.shape[1])\n",
        "          \n",
        "      return hidden_states, intensity_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar4NRCEyD4a4",
        "outputId": "0ba29eaf-30e0-4d1b-ae9d-b611f2ffb48d"
      },
      "source": [
        "# model evaluation\n",
        "\n",
        "# X_batch dimension = (batch_size, seq_len, n_features)\n",
        "X_batch = torch.tensor([[[1, 0.1],\n",
        "                         [0, 0.2],\n",
        "                         [0, 0.3],\n",
        "                         [1, 0.4],\n",
        "                         [0, 0.5],\n",
        "                         [0, 0.6],\n",
        "                         [1, 0.7]],\n",
        "                        [[1, 1.0],\n",
        "                         [0, 0.8], \n",
        "                         [0, 0.6],\n",
        "                         [0, 0.4],\n",
        "                         [0, 0.2],\n",
        "                         [1, 0.1],\n",
        "                         [0, 0.2]]], dtype = torch.float)\n",
        "\n",
        "FIXED_BATCH_SIZE = 2 # our batch size is fixed for now\n",
        "SEQ_LEN = 7\n",
        "N_FEATURES = 2\n",
        "\n",
        "N_PARAMETERS = 2\n",
        "N_BASIS_FUNCTIONS = 4\n",
        "\n",
        "\n",
        "model = UNIPoint(FIXED_BATCH_SIZE, SEQ_LEN, N_FEATURES, N_PARAMETERS, N_BASIS_FUNCTIONS)\n",
        "print(model)\n",
        "hidden_states, intensity_values = model(X_batch)\n",
        "print()\n",
        "print('hidden_states')\n",
        "print(hidden_states) # contains all output for all timesteps\n",
        "print()\n",
        "print('intensity_values')\n",
        "print(intensity_values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIPoint(\n",
            "  (rnn): RNNCell(2, 1)\n",
            "  (h2p): Linear(in_features=1, out_features=8, bias=True)\n",
            "  (Softplus): Softplus(beta=1, threshold=20)\n",
            ")\n",
            "Sequence  1 out of 7\n",
            "Sequence  2 out of 7\n",
            "Sequence  3 out of 7\n",
            "Sequence  4 out of 7\n",
            "Sequence  5 out of 7\n",
            "Sequence  6 out of 7\n",
            "Sequence  7 out of 7\n",
            "\n",
            "hidden_states\n",
            "[tensor([[-0.7855],\n",
            "        [-0.8579]], grad_fn=<TanhBackward>), tensor([[0.5136],\n",
            "        [0.1098]], grad_fn=<TanhBackward>), tensor([[-0.5213],\n",
            "        [-0.4676]], grad_fn=<TanhBackward>), tensor([[-0.5383],\n",
            "        [ 0.1353]], grad_fn=<TanhBackward>), tensor([[ 0.1073],\n",
            "        [-0.1815]], grad_fn=<TanhBackward>), tensor([[-0.4660],\n",
            "        [-0.5516]], grad_fn=<TanhBackward>), tensor([[-0.7187],\n",
            "        [ 0.3599]], grad_fn=<TanhBackward>)]\n",
            "\n",
            "intensity_values\n",
            "[tensor([2.7563, 2.6279], grad_fn=<SoftplusBackward>), tensor([1.3954, 1.9241], grad_fn=<SoftplusBackward>), tensor([2.3411, 2.3220], grad_fn=<SoftplusBackward>), tensor([2.3647, 1.7799], grad_fn=<SoftplusBackward>), tensor([1.8335, 2.0072], grad_fn=<SoftplusBackward>), tensor([2.3207, 2.3552], grad_fn=<SoftplusBackward>), tensor([2.5309, 1.5230], grad_fn=<SoftplusBackward>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiiBgub3YJJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrjhaGoRYJHN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo991CbiX3lB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ppr0HycX3r_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_w3sLlXX3xF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
