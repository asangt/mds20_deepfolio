# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HpDrYfebGHN4EVJl-Z_GDTZ9npmrKhAd
"""

import torch
import torch.nn as nn
from torch.nn import functional as F
from torch import optim

import numpy as np

# UNIPoint model
#-------------------------------------------------------
# dimensions be like:
#-------------------------------------------------------
# input -> hidden state -> parameters -> basis functions -> intensity function (output)
#-------------------------------------------------------
# (batch_size, seq_len, n_features) -> [for iteration we take input] (batch_size, 1, n_features) ->
# -> (batch_size, 1, 1) -> (batch_size, 1, n_parameters * n_basis_functions) -> 
# -> (batch_size, 1, n_basis_functions) -> (batch_size, 1, 1) 
#-------------------------------------------------------


class UNIPoint(nn.Module):
    def __init__(self, batch_size, seq_len, n_features, n_parameters, n_basis_functions):
      """
      Input parameters:
      n_neurons - number of neurons inside RNN
      n_parameters - expecteed number of parameters in basis function
      n_basis_functions - number of basis functions
      """
      super(UNIPoint, self).__init__()

      self.rnn = nn.RNNCell(n_features, 1)
      self.hx = torch.randn(batch_size, 1) # initialize hidden state 
      self.h2p = nn.Linear(1, n_parameters * n_basis_functions)
      self.basis_res = torch.randn(batch_size, n_basis_functions) #initialize matrix for basis f-s calculations results
      self.Softplus = torch.nn.Softplus(beta = 1)
      self.n_basis_functions = n_basis_functions

    def ReLU(self, parameter_1, parameter_2, time):
      """Function to apply Rectified Linear Unit (ReLU) as basis function inside network 
        Input parameters:
          parameters - alpha, beta for basis function's value calculation
          time - column-vector with time which had been spent since the begining of 
                  temporal point process (TPP)
      """
      self.output = torch.relu(self.parameters[:,parameter_1] * time + self.parameters[:,parameter_2] ) 
      return self.output
    
    def PowerLaw(self, parameter_1, parameter_2, time): # need to fix (see ReLU parameters and do the same)
      """Function to apply Power Law (PL) as basis function inside network 
        Input parameters:
          parameters - alpha, beta for basis function's value calculation
          time - column-vector with time which had been spent since the begining of 
                  temporal point process (TPP)
      """
      self.output = self.parameters[:,parameter_1] * (1 + time)**( - self.parameters[:,parameter_2])
      return self.output


    def forward(self, X, time):
      """Input parameters:
          X - batch with data 
          time - column-vector with interarrival time in temporal point process (TPP)
      """
        
      output = []

      print("------------Learning process starts here------------")
      print()
      # for each time step (here X shape is (batch_size, seq_len, n_features) )
      for i in range(X.shape[1]):

          #print(X[:,i,:].shape, 'is X shape')
          #print(self.hx.shape, 'is self.hx shape')
          self.hx = self.rnn(X[:,i,:], self.hx)
          self.parameters = self.h2p(self.hx)
          
          for function in range(self.n_basis_functions): 
              # calculating numbers of parameters to take for basis function
              par1 = 2 * function
              par2 = 2 * function + 1
              
              #print("'function' iterator value is ", function)
              #print('par1, par2 are ', par1, par2)
              #print('X[:,i,:] shape is ', X[:,i,:].shape)
              #print()
              #print(self.basis_res[:, function].shape, 'is a shape of self.basis_res[:, function]')
              self.basis_res[:, function] = self.ReLU(par1, par2, X[:,i,1]) # here X[:,i,1] - tau
          
          self.sum_res = torch.sum(self.basis_res, 1)

          self.intensity_res = self.Softplus(self.sum_res)

          output.append(self.hx)
          
          print("Epoch", i+1, "out of", X.shape[1])
          print()

      print("------------Learning process is finished------------")

      return output, self.hx, self.parameters, self.basis_res, self.sum_res, self.intensity_res

