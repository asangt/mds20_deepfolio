{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hawkes_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhCoO8BW-5ku"
      },
      "source": [
        "IN_COLAB = True if 'google.colab' in str(get_ipython()) else False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8WiyCSxdx1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM0pihc3_LN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e5c9c1-8968-4fc5-c4ee-dcd903bf9fa8"
      },
      "source": [
        "if IN_COLAB:\n",
        "  !pip install -q pytorch-lightning\n",
        "\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 563kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 39.2MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxnUz3QIRzrl"
      },
      "source": [
        "# ALL GLOBAL VARIABLES\n",
        "\n",
        "GLOBAL_DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "GLOBAL_SEED = 42\n",
        "PADDING_CONST = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtGHuZygfosD"
      },
      "source": [
        "def compute_integral_mc(cond_lam, mc_type_lam, time, src_padding_mask, type_encoding, alpha=-0.1, n_samples=100):\n",
        "    \"\"\"\n",
        "    Compute integral using Monte Carlo integration.\n",
        "    \"\"\"\n",
        "    dt = (time[:, 1:] - time[:, :-1]) * (~src_padding_mask[:, 1:])\n",
        "\n",
        "    # compute u used in eq. (9) from the paper\n",
        "    u = dt.unsqueeze(2) * torch.rand([*dt.size(), n_samples], device=cond_lam.device) / (time[:, :-1] + 1).unsqueeze(2)\n",
        "\n",
        "    # compute lambda(u)\n",
        "    softplus = nn.Softplus(threshold=10)\n",
        "    mc_cond_lam = softplus( alpha * u + mc_type_lam ).sum(dim=2) / n_samples\n",
        "\n",
        "    integral = dt * mc_cond_lam\n",
        "\n",
        "    return integral"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IzlD9rB_WlT"
      },
      "source": [
        "class HawkesTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_event_types, device, d_model=512, n_heads=8, n_layers=6, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Input parameters:\n",
        "          n_event_types (int) - number of event types in the data,\n",
        "          d_model (int) - size of model's latent dimension,\n",
        "          n_heads (int) - number of heads in the Multihead Attention module,\n",
        "          n_layers (int) - number of Transformer encoder layers,\n",
        "          dropout (float) - dropout rate\n",
        "        \"\"\"\n",
        "        super(HawkesTransformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.device = device\n",
        "\n",
        "        # initialize div term for temporal encoding\n",
        "        self.init_temporal_encoding()\n",
        "\n",
        "        # event type embedding\n",
        "        self.event_embedding = nn.Embedding(n_event_types + 1, d_model, padding_idx=PADDING_CONST)\n",
        "\n",
        "        # transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads)\n",
        "        layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.transformer_layers = nn.TransformerEncoder(encoder_layer, n_layers, norm=layer_norm)\n",
        "\n",
        "        # linear transformation of hidden states (\"history\" and \"base\" terms in eq.(6) of the THP paper)\n",
        "        self.transform = nn.Linear(d_model, n_event_types)\n",
        "        self.softplus = nn.Softplus(threshold=10)\n",
        "\n",
        "        # output prediction layers\n",
        "        self.time_predictor  = nn.Linear(d_model, 1)\n",
        "        self.event_predictor = nn.Linear(d_model, n_event_types)\n",
        "\n",
        "        # small constant\n",
        "        self.eps = torch.tensor([1e-8], device=self.device)\n",
        "\n",
        "    def generate_subsequent_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Function to generate masking for the subsequent information in the sequences (masked self-attention).\n",
        "        Input:\n",
        "          seq (B, S, F) - batch of sequences.\n",
        "        \"\"\"\n",
        "        bs, ls = seq.size()\n",
        "        subsequent_mask = torch.triu( torch.ones(ls, ls, device=self.device, dtype=torch.bool), diagonal=1 )\n",
        "        \n",
        "        return subsequent_mask\n",
        "    \n",
        "    def generate_key_padding_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Masking the padded part of the sequence.\n",
        "        Input:\n",
        "          seq (B, S, F) - batch of sequences.\n",
        "        \"\"\"\n",
        "        ls = seq.size(1)\n",
        "        padding_mask = seq.eq(PADDING_CONST)\n",
        "\n",
        "        return padding_mask\n",
        "\n",
        "    def init_temporal_encoding(self):\n",
        "        \"\"\"\n",
        "        Initializing the internal temporal encoding tensors.\n",
        "        \"\"\"\n",
        "        encoding_constant = torch.tensor(10000.0)\n",
        "\n",
        "        # for better numerical stability\n",
        "        self.te_div_term = torch.exp(2.0 * (torch.arange(0, self.d_model) // 2) * -torch.log(encoding_constant) / self.d_model).to(self.device)\n",
        "  \n",
        "    def temporal_encoding(self, t, non_padded_mask):\n",
        "        \"\"\"\n",
        "        Function to perform the temporal encoding on input timestamps.\n",
        "        Input:\n",
        "          t (B, S) - batch of timestamp sequences,\n",
        "          non_padded_mask (B, S) - binary mask indicating whether element is a padding (True) or not (False)\n",
        "        Output:\n",
        "          x (B, S, d_model) - raw model output,\n",
        "          lam (B, S, F) - intensity function,\n",
        "          time_pred (B, S) - timestamp prediction for the next event,\n",
        "          event_pred (B, S, n_event_types) - probabilities of event types\n",
        "        \"\"\"\n",
        "        temporal_enc = t.unsqueeze(-1) * self.te_div_term\n",
        "\n",
        "        temporal_enc[:, :, 0::2] = torch.sin(temporal_enc[:, :, 0::2])\n",
        "        temporal_enc[:, :, 1::2] = torch.cos(temporal_enc[:, :, 1::2])\n",
        "\n",
        "        return temporal_enc * non_padded_mask.unsqueeze(-1)\n",
        "    \n",
        "    def forward(self, input_seq):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "          input_seq (B, S, F) - input sequence of size (batch size, sequence length, features)\n",
        "        \"\"\"\n",
        "        bs, ls, nf = input_seq.size()\n",
        "\n",
        "        # generate masks\n",
        "        src_key_padding_mask = self.generate_key_padding_mask(input_seq[:,:,1])\n",
        "        src_non_padded_mask = ~src_key_padding_mask\n",
        "        src_mask = self.generate_subsequent_mask(input_seq[:,:,1])\n",
        "\n",
        "        # perform encodings\n",
        "        temp_enc  = self.temporal_encoding(input_seq[:,:,0], src_non_padded_mask)\n",
        "        event_enc = self.event_embedding(input_seq[:,:,1])\n",
        "\n",
        "        # make pass through transformer encoder layers\n",
        "        x = event_enc + temp_enc\n",
        "        x = self.transformer_layers(x.permute(1, 0, 2), mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
        "        x = x.permute(1, 0, 2)\n",
        "\n",
        "        # calculate type-specific intensity function\n",
        "        lam = self.softplus(self.transform(x))\n",
        "\n",
        "        # make predictions\n",
        "        time_pred  = self.time_predictor(x).squeeze(2) * src_non_padded_mask\n",
        "        event_pred = self.event_predictor(x) * src_non_padded_mask.unsqueeze(-1)\n",
        "\n",
        "        return x, lam, (time_pred, event_pred)\n",
        "    \n",
        "\n",
        "    def loss_function(self, x, lam, time_pred, event_pred, tgt_seq, alpha=-0.1):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "          x (B, S, d_model) - raw network output,\n",
        "          lam (B, S, F) - type specific intensity functions,\n",
        "          tgt_seq (B, S, F) - original sequence of size (batch size, sequence length, features),\n",
        "          alpha (float) - weight coefficient for \"current\" influence in eq. (6) from the paper\n",
        "        \"\"\"\n",
        "\n",
        "        bs, ls, nf = tgt_seq.size()\n",
        "        type_encoding = torch.zeros(bs, ls, nf, device=self.device)\n",
        "        for k in range(nf):\n",
        "            type_encoding[:, :, k] = (tgt_seq[:, :, 1] == k + 1).bool().to(self.device)\n",
        "        src_padding_mask = self.generate_key_padding_mask(tgt_seq[:,:,1])\n",
        "\n",
        "        # compute conditional intensity function\n",
        "        cond_lam = (lam * type_encoding).sum(dim=2)\n",
        "\n",
        "        # compute event log-likelihood\n",
        "        event_part = (cond_lam + self.eps).masked_fill_(src_padding_mask, 1.0).log()\n",
        "        event_part = event_part.sum(dim=1)\n",
        "\n",
        "        # compute non-event log-likelihood\n",
        "\n",
        "        # compute lambda for (t_{j+1}) for M-C integration\n",
        "        mc_type_lam = self.transform(x[:, 1:, :])\n",
        "        mc_type_lam = (mc_type_lam * type_encoding[:, 1:, :]).sum(dim=2, keepdim=True)\n",
        "\n",
        "        non_event_part = compute_integral_mc(cond_lam, mc_type_lam, tgt_seq[:,:,0], src_padding_mask, type_encoding, alpha).sum(dim=1)\n",
        "\n",
        "        # compute total log-likelihood\n",
        "        log_likelihood = event_part - non_event_part\n",
        "\n",
        "        # compute timestamp forecasting error\n",
        "\n",
        "        scale = 0.01 # for numerical stability\n",
        "        time_ground_truth = tgt_seq[:, 1:, 0] - tgt_seq[:, :-1, 0]\n",
        "        time_pred = time_pred[:, :-1]\n",
        "\n",
        "        time_error = nn.MSELoss(reduction='none')(time_pred, time_ground_truth).sum(dim=1)\n",
        "\n",
        "        # compute event prediction error through cross entropy loss\n",
        "\n",
        "        event_ground_truth = tgt_seq[:, 1:, 1] - 1\n",
        "        event_pred = event_pred[:, :-1, :]\n",
        "\n",
        "        event_error  = nn.CrossEntropyLoss(reduction='none', ignore_index=-1)(event_pred.transpose(1, 2), event_ground_truth).sum(dim=1)\n",
        "\n",
        "        return (-log_likelihood + event_error + time_error * scale).mean()"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65WgHZVyuCxB"
      },
      "source": [
        "X_batch = torch.tensor([[[1, 1], [2, 2], \n",
        "                         [4, 2], [5, 1]],\n",
        "                        [[7, 1], [8, 1], \n",
        "                         [10, 2], [11, 1]]], dtype = torch.long) # X0 and X1"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqGnHfNQ_HX"
      },
      "source": [
        "transformer = HawkesTransformer(2, torch.device('cpu'))\n",
        "x, lam, preds = transformer(X_batch)"
      ],
      "execution_count": 174,
      "outputs": []
    }
  ]
}