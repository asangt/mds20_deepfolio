{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hawkes_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8WiyCSxdx1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxnUz3QIRzrl"
      },
      "source": [
        "# ALL GLOBAL VARIABLES\n",
        "\n",
        "GLOBAL_DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "GLOBAL_SEED = 42\n",
        "PADDING_CONST = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nrkp8nHOpV9",
        "outputId": "1bffa5c8-e8e5-402b-a409-e9603034300c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec  7 18:52:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    32W / 250W |   1593MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYI4Wtuddst-"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtGHuZygfosD"
      },
      "source": [
        "def compute_integral_mc(intensity_network, hidden_states, cond_lam, src_padding_mask, time, events, alpha=-0.1, n_samples=100):\n",
        "    \"\"\"\n",
        "    Compute integral using Monte Carlo integration.\n",
        "    \"\"\"\n",
        "    # time differences (t_{j} - t{j-1})\n",
        "    dt = (time[:, 1:] - time[:, :-1]) * (~src_padding_mask[:, 1:])\n",
        "\n",
        "    # sample t from uniform distribution: \n",
        "    # since t \\in (t_{j-1}, t_j) which would lead to (t - t_{j-1}) / t_{j-1} \\in [0, (t_j - t_{j-1}) / t_{j-1}),\n",
        "    # we can reformulate this as (t_j - t_{j-1}) / t_{j-1} * u, where u \\in [0, 1)\n",
        "    current_influence = alpha * (dt.unsqueeze(2) / (time[:, :-1] + 1).unsqueeze(2)) * torch.rand([*dt.size(), n_samples], device=cond_lam.device)\n",
        "\n",
        "    # compute sum( lambda(u_i) ) / N\n",
        "    mc_intensity = intensity_network(hidden_states, events, current_inf=current_influence, mc_trick=True)\n",
        "\n",
        "    return dt * mc_intensity\n",
        "\n",
        "def compute_integral_li(lam, time, src_padding_mask):\n",
        "    dt = (time[:, 1:] - time[:, :-1]) * (~src_padding_mask[:, 1:])\n",
        "    dlam = (lam[:, 1:] - lam[:, :-1]) * (~src_padding_mask[:, 1:])\n",
        "\n",
        "    integral = dt * dlam\n",
        "    return 0.5 * integral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbcIj2j2NJrb"
      },
      "source": [
        "class IntensityNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, n_event_types, device):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            hidden_size (int) - size of the hidden dimension (d_model),\n",
        "            n_event_types (int) - number of possible event types in the data\n",
        "        \"\"\"\n",
        "        super(IntensityNetwork, self).__init__()\n",
        "\n",
        "        self.n_events = n_event_types\n",
        "        self.device = device\n",
        "\n",
        "        # accounts for \"history\" and \"base\" (through bias) terms in eq.(6) of the paper\n",
        "        self.linear = nn.Linear(hidden_size, n_event_types)\n",
        "        self.softplus = nn.Softplus(threshold=10)\n",
        "\n",
        "    def generate_type_mask(self, events):\n",
        "        bs, ls = events.size()\n",
        "\n",
        "        type_mask = torch.zeros(bs, ls, self.n_events, device=self.device)\n",
        "        for k in range(self.n_events):\n",
        "            type_mask[:, :, k] = (events == k + 1).bool().to(self.device)\n",
        "        return type_mask\n",
        "    \n",
        "    def forward(self, hidden_states, events, current_inf=None, mc_trick=False):\n",
        "        intensity_terms = self.linear(hidden_states)\n",
        "        type_mask = self.generate_type_mask(events)\n",
        "\n",
        "        if mc_trick:\n",
        "            # this is a trick for Monte-Carlo integration, which allows to vectorize\n",
        "            # computation of (num_samples) intensity functions instead of making a loop\n",
        "\n",
        "            assert current_inf is not None, \"current influence cannot be None when mc_trick is True\"\n",
        "\n",
        "            intensity_terms = (intensity_terms[:, :-1, :] * type_mask[:, :-1, :]).sum(dim=2, keepdim=True)\n",
        "            continious_intensity = self.softplus( intensity_terms + current_inf )\n",
        "            conditional_lambda = continious_intensity.mean(dim=2)\n",
        "        else:\n",
        "            if current_inf is not None:\n",
        "                intensity_terms += current_inf\n",
        "            continious_intensity = self.softplus(intensity_terms)\n",
        "\n",
        "            # (continious_intensity * type_mask) gets type-specific instensity function (eq. (6))\n",
        "            # after summation along the 2nd dimension, conditional intensity function is obtained\n",
        "            conditional_lambda = (continious_intensity * type_mask).sum(dim=2)\n",
        "        \n",
        "        return conditional_lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IzlD9rB_WlT"
      },
      "source": [
        "class HawkesTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_event_types, device, d_model=512, n_heads=8, dim_feedforward=2048, n_layers=6, dropout=0.1, activation='relu'):\n",
        "        \"\"\"\n",
        "        Input parameters:\n",
        "          n_event_types (int) - number of event types in the data,\n",
        "          d_model (int) - size of model's latent dimension,\n",
        "          n_heads (int) - number of heads in the Multihead Attention module,\n",
        "          dim_feedforward (int) - size of the feedforward network dimension,\n",
        "          n_layers (int) - number of Transformer encoder layers,\n",
        "          dropout (float) - dropout rate,\n",
        "          activation (string) - activation function for the feedforward network (relu or gelu)\n",
        "        \"\"\"\n",
        "        super(HawkesTransformer, self).__init__()\n",
        "\n",
        "        self.n_events = n_event_types\n",
        "        self.d_model = d_model\n",
        "        self.device = device\n",
        "\n",
        "        # initialize div term for temporal encoding\n",
        "        self.init_temporal_encoding()\n",
        "\n",
        "        # event type embedding\n",
        "        self.event_embedding = nn.Embedding(n_event_types + 1, d_model, padding_idx=PADDING_CONST)\n",
        "\n",
        "        # transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward, dropout, activation)\n",
        "        self.transformer_layers = nn.TransformerEncoder(encoder_layer, n_layers)\n",
        "\n",
        "        # linear transformation of hidden states (\"history\" and \"base\" terms in eq.(6) of the THP paper) to\n",
        "        # type specific intensity\n",
        "        self.intensity_layer = IntensityNetwork(d_model, n_event_types, self.device)\n",
        "\n",
        "        # output prediction layers\n",
        "        self.time_predictor  = nn.Linear(d_model, 1, bias=False)\n",
        "        self.event_predictor = nn.Linear(d_model, n_event_types, bias=False)\n",
        "\n",
        "        # small constant\n",
        "        self.eps = torch.tensor([1e-8], device=self.device)\n",
        "\n",
        "    def generate_subsequent_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Function to generate masking for the subsequent information in the sequences (masked self-attention).\n",
        "        Input:\n",
        "          seq (B, S, F) - batch of sequences.\n",
        "        \"\"\"\n",
        "        bs, ls = seq.size()\n",
        "        subsequent_mask = torch.triu( torch.ones(ls, ls, device=self.device, dtype=torch.bool), diagonal=1 )\n",
        "        \n",
        "        return subsequent_mask\n",
        "    \n",
        "    def generate_key_padding_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Masking the padded part of the sequence.\n",
        "        Input:\n",
        "          seq (B, S, F) - batch of sequences.\n",
        "        \"\"\"\n",
        "        ls = seq.size(1)\n",
        "        padding_mask = seq.eq(PADDING_CONST)\n",
        "\n",
        "        return padding_mask\n",
        "\n",
        "    def init_temporal_encoding(self):\n",
        "        \"\"\"\n",
        "        Initializing the internal temporal encoding tensors.\n",
        "        \"\"\"\n",
        "        encoding_constant = torch.tensor(10000.0)\n",
        "\n",
        "        # for better numerical stability\n",
        "        self.te_div_term = torch.exp(2.0 * (torch.arange(0, self.d_model) // 2) * -torch.log(encoding_constant) / self.d_model).to(self.device)\n",
        "  \n",
        "    def temporal_encoding(self, t, non_padded_mask):\n",
        "        \"\"\"\n",
        "        Function to perform the temporal encoding on input timestamps.\n",
        "        Input:\n",
        "          t (B, S) - batch of timestamp sequences,\n",
        "          non_padded_mask (B, S) - binary mask indicating whether element is a padding (True) or not (False)\n",
        "        Output:\n",
        "          x (B, S, d_model) - raw model output,\n",
        "          lam (B, S, F) - intensity function,\n",
        "          time_pred (B, S) - timestamp prediction for the next event,\n",
        "          event_pred (B, S, n_event_types) - probabilities of event types\n",
        "        \"\"\"\n",
        "        temporal_enc = t.unsqueeze(-1) * self.te_div_term\n",
        "\n",
        "        temporal_enc[:, :, 0::2] = torch.sin(temporal_enc[:, :, 0::2])\n",
        "        temporal_enc[:, :, 1::2] = torch.cos(temporal_enc[:, :, 1::2])\n",
        "\n",
        "        return temporal_enc * non_padded_mask.unsqueeze(-1)\n",
        "    \n",
        "    def log_likelihood(self, hidden_states, cond_lam, time, events, alpha, integral='mc'):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            hidden_states (B, S, E) - hidden states of the network,\n",
        "            cond_lam (B, S, F) - conditional intensity function,\n",
        "            time (B, S) - ground truth for times,\n",
        "            events (B, S) - ground truth for event types,\n",
        "            alpha (int) - scaling constant,\n",
        "            integral (string) - method of integration: either Monte-Carlo or linear interpolation\n",
        "        \"\"\"\n",
        "        \n",
        "        src_padding_mask = self.generate_key_padding_mask(events)\n",
        "\n",
        "        # compute event log-likelihood\n",
        "        event_part = cond_lam + self.eps\n",
        "        event_part.masked_fill_(src_padding_mask, 1.0)\n",
        "        event_part = event_part.log()\n",
        "        event_part = event_part.sum(dim=1)\n",
        "\n",
        "        # compute non-event log-likelihood\n",
        "        if integral == 'mc':\n",
        "            non_event_part = compute_integral_mc(self.intensity_layer, hidden_states, cond_lam, src_padding_mask, time, events, alpha)\n",
        "        else:\n",
        "            non_event_part = compute_integral_li(cond_lam, time, src_padding_mask)\n",
        "        non_event_part = non_event_part.sum(dim=1)\n",
        "\n",
        "        # compute total log-likelihood\n",
        "        log_likelihood = (event_part - non_event_part).sum()\n",
        "\n",
        "        return log_likelihood\n",
        "\n",
        "    def time_error(self, time_pred, time):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            time_pred (B, S) - time predictions,\n",
        "            time (B, S) - ground truth for times\n",
        "        \"\"\"\n",
        "\n",
        "        time_ground_truth = time[:, 1:] - time[:, :-1]\n",
        "        time_pred = time_pred[:, :-1]\n",
        "\n",
        "        time_error = nn.MSELoss(reduction='sum')(time_pred, time_ground_truth)\n",
        "        return time_error\n",
        "\n",
        "    def event_error(self, event_pred, events):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            event_pred (B, S, K) - event probabilities predictions,\n",
        "            events (B, S) - ground truth for event types,\n",
        "        \"\"\"\n",
        "\n",
        "        event_ground_truth = events[:, 1:] - 1\n",
        "        event_pred = event_pred[:, :-1, :]\n",
        "\n",
        "        event_error = nn.CrossEntropyLoss(reduction='sum', ignore_index=-1)(event_pred.transpose(1, 2), event_ground_truth)\n",
        "        return event_error\n",
        "\n",
        "    def loss_function(self, hidden_states, cond_lam, time_pred, event_pred, time, events, alpha=-0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            hidden_states (B, S, E) - hidden states of the network,\n",
        "            cond_lam (B, S, F) - conditional intensity function,\n",
        "            time_pred (B, S) - time predictions,\n",
        "            event_pred (B, S, K) - event probabilities predictions,\n",
        "            time (B, S) - ground truth for times,\n",
        "            events (B, S) - ground truth for event types,\n",
        "            alpha (int) - scaling constant\n",
        "        \"\"\"\n",
        "\n",
        "        # compute log-likelihood\n",
        "        log_likelihood = self.log_likelihood(hidden_states, cond_lam, time, events, alpha)\n",
        "\n",
        "        # compute timestamp forecasting error\n",
        "        time_error = self.time_error(time_pred, time)\n",
        "\n",
        "        # compute event prediction error through cross entropy loss\n",
        "        event_error = self.event_error(event_pred, events)\n",
        "\n",
        "        scale = 0.01 # for numerical stability\n",
        "        loss  = -log_likelihood + event_error + time_error * scale\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def forward(self, time, events):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "          input_seq (B, S, F) - input sequence of size (batch size, sequence length, features)\n",
        "        \"\"\"\n",
        "\n",
        "        # generate masks\n",
        "        src_key_padding_mask = self.generate_key_padding_mask(events)\n",
        "        src_non_padded_mask = ~src_key_padding_mask\n",
        "        src_mask = self.generate_subsequent_mask(events)\n",
        "\n",
        "        # perform encodings\n",
        "        temp_enc  = self.temporal_encoding(time, src_non_padded_mask)\n",
        "        event_enc = self.event_embedding(events)\n",
        "\n",
        "        # make pass through transformer encoder layers\n",
        "        h = event_enc + temp_enc\n",
        "        h = self.transformer_layers(h.permute(1, 0, 2), mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
        "        h = h.permute(1, 0, 2)\n",
        "\n",
        "        # obtain conditional intensity function\n",
        "        cond_lam = self.intensity_layer(h, events)\n",
        "\n",
        "        # make predictions\n",
        "        time_pred  = self.time_predictor(h).squeeze(2) * src_non_padded_mask\n",
        "        event_pred = self.event_predictor(h) * src_non_padded_mask.unsqueeze(-1)\n",
        "\n",
        "        return h, cond_lam, time_pred, event_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d100mIrBR34l"
      },
      "source": [
        "def run_epoch(model, dataloader, device, optimizer=None, metric=None):\n",
        "    epoch_loss = 0.\n",
        "    metric = 0.\n",
        "    with torch.set_grad_enabled(optimizer is not None):\n",
        "        for time, events in dataloader:\n",
        "            time = time.to(device)\n",
        "            events = events.to(device)\n",
        "\n",
        "            h, cond_lam, time_pred, event_pred = model(time, events)\n",
        "            #loss = model.loss_function(h, cond_lam, time_pred, event_pred, time, events)\n",
        "            loss = -model.log_likelihood(h, cond_lam, time, events, -0.1, 'li') + model.event_error(event_pred, events)\n",
        "\n",
        "            if optimizer is not None:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            epoch_loss += loss.item() / (events.shape[1] * events.shape[0])\n",
        "\n",
        "            if metric is not None:\n",
        "                metric += (event_pred.softmax(dim=2).argmax(dim=2)[:, :-1] == events[:, 1:] - 1).sum() / ((events.shape[1] - 1) * events.shape[0])\n",
        "    epoch_loss /= len(dataloader)\n",
        "    metric /= len(dataloader)\n",
        "\n",
        "    return epoch_loss, metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Chfl0K2QRnk"
      },
      "source": [
        "import time as t\n",
        "\n",
        "def train(model, n_epochs, optimizer, train_loader, val_loader, scheduler=None, device=None, verbose=True, freq=None, compute_metric=False):\n",
        "    if verbose and freq is None:\n",
        "        freq = max(n_epochs // 10, 1)\n",
        "    if device is None:\n",
        "        device = GLOBAL_DEVICE\n",
        "\n",
        "    train_loss_history, val_loss_history = [], []\n",
        "    train_metric_history, val_metric_history = [], []\n",
        "\n",
        "    time_start = t.time()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        train_loss, train_metric = run_epoch(model, train_loader, device, optimizer, metric=compute_metric)\n",
        "        train_loss_history.append( train_loss )\n",
        "        train_metric_history.append( train_metric )\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_metric = run_epoch(model, val_loader, device, metric=compute_metric)\n",
        "        val_loss_history.append( val_loss )\n",
        "        val_metric_history.append( val_metric )\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        time_epoch_end = t.time() - time_start\n",
        "        if verbose and epoch % freq == 0:\n",
        "            print(\"Epoch {}: train loss - {:.3f} | validation loss - {:.3f}\".format(epoch, train_loss_history[-1], val_loss_history[-1]))\n",
        "            if compute_metric > 0:\n",
        "                print(\"train accuracy - {:.3f} | validation accuracy - {:.3f}\".format(train_metric_history[-1], val_metric_history[-1]))\n",
        "            print(\"Time elapsed: {:.2f} s\".format(time_epoch_end))\n",
        "\n",
        "    return train_loss_history, val_loss_history, train_metric_history, val_metric_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcW8ryPzVL7D"
      },
      "source": [
        "!unzip -q fin_data.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov7o0hyHWUG1"
      },
      "source": [
        "import pickle\n",
        "\n",
        "class NHPDataset(utils_data.Dataset):\n",
        "    ''' \n",
        "    Create Dataset for Neural Hawkey Process\n",
        "    '''\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        self.event_type = []\n",
        "        self.event_time = []\n",
        "\n",
        "        with open(file_path, 'rb') as f:\n",
        "\n",
        "            if 'dev' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['dev']\n",
        "            elif 'train' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['train']\n",
        "            elif 'test' in file_path:\n",
        "                seqs = pickle.load(f, encoding='latin1')['test']\n",
        "\n",
        "            for idx, seq in enumerate(seqs):\n",
        "                self.event_type.append(torch.Tensor([int(event['type_event']) for event in seq]))\n",
        "                self.event_time.append(torch.Tensor([float(event['time_since_last_event']) for event in seq]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.event_type)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        event_type = torch.LongTensor(self.event_type[index].long() + 1)\n",
        "        event_time = torch.Tensor(self.event_time[index])\n",
        "        seq_len = torch.tensor(len(event_type))\n",
        "        event_last_time = torch.sum(event_time)\n",
        "\n",
        "        X = torch.stack((event_time, event_type), dim=1)\n",
        "        \n",
        "        return event_time, event_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttnAtcwBXuLm"
      },
      "source": [
        "train_dataset = NHPDataset('data/train.pkl')\n",
        "val_dataset = NHPDataset('data/dev.pkl')\n",
        "test_dataset = NHPDataset('data/test.pkl')\n",
        "\n",
        "train_loader = utils_data.DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "val_loader = utils_data.DataLoader(val_dataset, batch_size=5, shuffle=False)\n",
        "test_loader = utils_data.DataLoader(test_dataset, batch_size=5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn1UweNSaayy",
        "outputId": "668d5540-3ba3-450e-e938-a8cbd71d6698"
      },
      "source": [
        "model = HawkesTransformer(2, GLOBAL_DEVICE, 512, 4, 1024, 4, 0.1, 'gelu').to(GLOBAL_DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-05)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.5)\n",
        "\n",
        "train_loss_hist, val_loss_hist, train_metric_hist, val_metric_hist = train(model, 50, optimizer, train_loader, val_loader, scheduler, GLOBAL_DEVICE, freq=1, compute_metric=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss - -2.110 | validation loss - -3.519\n",
            "train accuracy - 0.591 | validation accuracy - 0.584\n",
            "Time elapsed: 10.65 s\n",
            "Epoch 2: train loss - -8.328 | validation loss - -4.347\n",
            "train accuracy - 0.615 | validation accuracy - 0.599\n",
            "Time elapsed: 21.29 s\n",
            "Epoch 3: train loss - -9.765 | validation loss - -4.820\n",
            "train accuracy - 0.620 | validation accuracy - 0.599\n",
            "Time elapsed: 31.92 s\n",
            "Epoch 4: train loss - -10.620 | validation loss - -5.470\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 42.55 s\n",
            "Epoch 5: train loss - -11.255 | validation loss - -5.367\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 53.18 s\n",
            "Epoch 6: train loss - -11.717 | validation loss - -5.602\n",
            "train accuracy - 0.619 | validation accuracy - 0.599\n",
            "Time elapsed: 63.81 s\n",
            "Epoch 7: train loss - -12.767 | validation loss - -5.816\n",
            "train accuracy - 0.620 | validation accuracy - 0.599\n",
            "Time elapsed: 74.45 s\n",
            "Epoch 8: train loss - -13.414 | validation loss - -6.154\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 85.08 s\n",
            "Epoch 9: train loss - -14.331 | validation loss - -6.398\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 95.71 s\n",
            "Epoch 10: train loss - -14.982 | validation loss - -7.132\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 106.34 s\n",
            "Epoch 11: train loss - -15.764 | validation loss - -7.112\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 116.96 s\n",
            "Epoch 12: train loss - -16.364 | validation loss - -7.457\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 127.60 s\n",
            "Epoch 13: train loss - -16.850 | validation loss - -7.510\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 138.23 s\n",
            "Epoch 14: train loss - -17.196 | validation loss - -7.560\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 148.86 s\n",
            "Epoch 15: train loss - -17.561 | validation loss - -7.663\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 159.50 s\n",
            "Epoch 16: train loss - -18.130 | validation loss - -7.991\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 170.13 s\n",
            "Epoch 17: train loss - -18.605 | validation loss - -8.025\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 180.76 s\n",
            "Epoch 18: train loss - -19.038 | validation loss - -7.897\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 191.39 s\n",
            "Epoch 19: train loss - -19.132 | validation loss - -8.532\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 202.02 s\n",
            "Epoch 20: train loss - -18.864 | validation loss - -7.755\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 212.65 s\n",
            "Epoch 21: train loss - -19.510 | validation loss - -8.308\n",
            "train accuracy - 0.619 | validation accuracy - 0.599\n",
            "Time elapsed: 223.29 s\n",
            "Epoch 22: train loss - -19.874 | validation loss - -8.456\n",
            "train accuracy - 0.619 | validation accuracy - 0.598\n",
            "Time elapsed: 233.92 s\n",
            "Epoch 23: train loss - -20.194 | validation loss - -8.684\n",
            "train accuracy - 0.620 | validation accuracy - 0.599\n",
            "Time elapsed: 244.56 s\n",
            "Epoch 24: train loss - -20.409 | validation loss - -8.773\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 255.20 s\n",
            "Epoch 25: train loss - -20.692 | validation loss - -8.864\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 265.83 s\n",
            "Epoch 26: train loss - -20.926 | validation loss - -9.029\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 276.46 s\n",
            "Epoch 27: train loss - -20.977 | validation loss - -9.089\n",
            "train accuracy - 0.620 | validation accuracy - 0.599\n",
            "Time elapsed: 287.09 s\n",
            "Epoch 28: train loss - -21.355 | validation loss - -9.140\n",
            "train accuracy - 0.620 | validation accuracy - 0.599\n",
            "Time elapsed: 297.72 s\n",
            "Epoch 29: train loss - -21.553 | validation loss - -9.225\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 308.35 s\n",
            "Epoch 30: train loss - -21.693 | validation loss - -9.287\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 318.98 s\n",
            "Epoch 31: train loss - -21.470 | validation loss - -9.312\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 329.61 s\n",
            "Epoch 32: train loss - -22.014 | validation loss - -9.417\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 340.24 s\n",
            "Epoch 33: train loss - -22.104 | validation loss - -9.432\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 350.88 s\n",
            "Epoch 34: train loss - -22.166 | validation loss - -9.436\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 361.51 s\n",
            "Epoch 35: train loss - -22.275 | validation loss - -9.417\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 372.13 s\n",
            "Epoch 36: train loss - -22.308 | validation loss - -9.520\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 382.77 s\n",
            "Epoch 37: train loss - -22.452 | validation loss - -9.564\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 393.40 s\n",
            "Epoch 38: train loss - -22.557 | validation loss - -9.570\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 404.03 s\n",
            "Epoch 39: train loss - -22.651 | validation loss - -9.659\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 414.66 s\n",
            "Epoch 40: train loss - -22.781 | validation loss - -9.731\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 425.30 s\n",
            "Epoch 41: train loss - -22.822 | validation loss - -9.724\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 435.93 s\n",
            "Epoch 42: train loss - -22.912 | validation loss - -9.737\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 446.56 s\n",
            "Epoch 43: train loss - -22.975 | validation loss - -9.767\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 457.20 s\n",
            "Epoch 44: train loss - -23.009 | validation loss - -9.749\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 467.83 s\n",
            "Epoch 45: train loss - -23.056 | validation loss - -9.704\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 478.46 s\n",
            "Epoch 46: train loss - -23.070 | validation loss - -9.779\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 489.10 s\n",
            "Epoch 47: train loss - -23.157 | validation loss - -9.803\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 499.73 s\n",
            "Epoch 48: train loss - -23.196 | validation loss - -9.827\n",
            "train accuracy - 0.622 | validation accuracy - 0.599\n",
            "Time elapsed: 510.36 s\n",
            "Epoch 49: train loss - -23.240 | validation loss - -9.825\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 521.00 s\n",
            "Epoch 50: train loss - -23.304 | validation loss - -9.864\n",
            "train accuracy - 0.621 | validation accuracy - 0.599\n",
            "Time elapsed: 531.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDMNXC3S9eLb"
      },
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXI1Ne8h9rqL"
      },
      "source": [
        "model = HawkesTransformer(2, GLOBAL_DEVICE)\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model.to(GLOBAL_DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irK8r-OOFAl"
      },
      "source": [
        "loss, metrics = run_epoch(model, val_loader, GLOBAL_DEVICE, metric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njNrs2eQPFjv",
        "outputId": "fa2052be-a977-484f-f9ce-f8b98a3702c7"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.863696708345888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}