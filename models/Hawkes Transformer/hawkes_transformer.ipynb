{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hawkes_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhCoO8BW-5ku"
      },
      "source": [
        "IN_COLAB = True if 'google.colab' in str(get_ipython()) else False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8WiyCSxdx1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM0pihc3_LN7"
      },
      "source": [
        "if IN_COLAB:\n",
        "  !pip install -q pytorch-lightning\n",
        "\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxnUz3QIRzrl"
      },
      "source": [
        "# ALL GLOBAL VARIABLES\n",
        "\n",
        "GLOBAL_DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "GLOBAL_SEED = 42\n",
        "PADDING_CONST = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IzlD9rB_WlT"
      },
      "source": [
        "class HawkesTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_event_types, device, d_model=512, n_heads=8, n_layers=6, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Input parameters:\n",
        "          n_event_types (int) - number of event types in the data,\n",
        "          d_model (int) - size of model's latent dimension,\n",
        "        \"\"\"\n",
        "        super(HawkesTransformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.device = device\n",
        "\n",
        "        # initialize div term for temporal encoding\n",
        "        self.init_temporal_encoding()\n",
        "\n",
        "        # event type embedding\n",
        "        self.event_embedding = nn.Embedding(n_event_types + 1, d_model, padding_idx=PADDING_CONST)\n",
        "\n",
        "        # transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads)\n",
        "        layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.transformer_layers = nn.TransformerEncoder(encoder_layer, n_layers, norm=layer_norm)\n",
        "\n",
        "        # output prediction layers\n",
        "        self.time_predictor  = nn.Linear(d_model, 1)\n",
        "        self.event_predictor = nn.Linear(d_model, n_event_types)\n",
        "\n",
        "    def generate_subsequent_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Function to generate masking for the subsequent information in the sequences (masked self-attention)\n",
        "        \"\"\"\n",
        "        bs, ls = seq.size()\n",
        "        subsequent_mask = ~torch.triu( torch.ones(ls, ls, device=self.device, dtype=torch.bool), diagonal=1 )\n",
        "        \n",
        "        return subsequent_mask\n",
        "    \n",
        "    def generate_key_padding_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Masking the padded part of the sequence.\n",
        "        \"\"\"\n",
        "        ls = seq.size(1)\n",
        "        padding_mask = seq.eq(PADDING_CONST)\n",
        "\n",
        "        return padding_mask\n",
        "\n",
        "    def init_temporal_encoding(self):\n",
        "        encoding_constant = torch.tensor(10000.0)\n",
        "\n",
        "        # for better numerical stability\n",
        "        self.te_div_term = torch.exp(2.0 * (torch.arange(0, self.d_model) // 2) * -torch.log(encoding_constant) / self.d_model).to(self.device)\n",
        "  \n",
        "    def temporal_encoding(self, t, non_padded_mask):\n",
        "        temporal_enc = t.unsqueeze(-1) * self.te_div_term\n",
        "\n",
        "        temporal_enc[:, :, 0::2] = torch.sin(temporal_enc[:, :, 0::2])\n",
        "        temporal_enc[:, :, 1::2] = torch.cos(temporal_enc[:, :, 1::2])\n",
        "\n",
        "        return temporal_enc * non_padded_mask.unsqueeze(-1)\n",
        "    \n",
        "    def forward(self, input_seq):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "          input_seq (B, S, F) - input sequence of size (batch size, sequence length, features)\n",
        "        \"\"\"\n",
        "        bs, ls, nf = input_seq.size()\n",
        "\n",
        "        # generate masks\n",
        "        src_key_padding_mask = self.generate_key_padding_mask(input_seq[:,:,1])\n",
        "        src_non_padded_mask = ~src_key_padding_mask\n",
        "        src_mask = self.generate_subsequent_mask(input_seq[:,:,1])\n",
        "\n",
        "        # perform encodings\n",
        "        temp_enc  = self.temporal_encoding(input_seq[:,:,0], src_non_padded_mask)\n",
        "        event_enc = self.event_embedding(input_seq[:,:,1])\n",
        "\n",
        "        # make pass through transformer encoder layers\n",
        "        x = event_enc + temp_enc\n",
        "        x = self.transformer_layers(x)\n",
        "\n",
        "        time_pred  = self.time_predictor(x).squeeze(2) * src_non_padded_mask\n",
        "        event_pred = self.event_predictor(x) * src_non_padded_mask.unsqueeze(-1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqGnHfNQ_HX"
      },
      "source": [
        "test_batch = torch.randint(low=1, high=3, size=(16, 20, 2))\n",
        "\n",
        "transformer = HawkesTransformer(2, torch.device('cpu'))\n",
        "transformer(test_batch).size()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}